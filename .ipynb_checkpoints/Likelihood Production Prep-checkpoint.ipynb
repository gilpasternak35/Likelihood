{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for project purposes\n",
    "# Full Project imports\n",
    "import pandas as pd\n",
    "import math as mt\n",
    "import dateutil\n",
    "from datetime import datetime, timedelta\n",
    "import requests as rd\n",
    "import numpy as np\n",
    "from sklearn import neighbors, decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import smtplib\n",
    "import scipy.stats as st\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bootstrap:\n",
    "    '''A class for returning anomaly of categorical column counts, utilizing the metric of surprise (entropy)'''\n",
    "    data = None\n",
    "    trainDf = None\n",
    "    testDf = None\n",
    "    timestamp = None\n",
    "    params = None\n",
    "    \n",
    "    # Overloaded constructor in case user doesn't want to fit data right away\n",
    "    def __init__(self, timeCol = 'date_time', resamples = 1000, maxTrainingSizeMult = 10, maxCategory = 100, minCategories = 10):\n",
    "        '''\n",
    "        Constructor which does not require immediate fit to model, merely initializes timestamp if given\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        timeCol: String - The name of the primary TimeStamp column\n",
    "        resamples: int - the number of times the bootstrap resamples. Making this very large will improve accuracy but significantly lower speed. Default = 1000\n",
    "        maxTrainingSizeMult: int - If there is more than x  = maxTrainingSizeMult ratio of training to test data, trim training data to most recent. Default = 10\n",
    "        maxCategory: int - Maximum number of categories in a column (to ensure that counts are not tiny and are meaninful), column skipped if value count higher than this. Default = 100\n",
    "        minCategory: int - if column has a category count that is lower than this value, don't report it in bootstrap surprise. Default = 10.\n",
    "        '''\n",
    "        # Initializing time\n",
    "        timestamp = timeCol\n",
    "        \n",
    "        # Meta-parameter initialization\n",
    "        params = {\n",
    "          \"bootstrapResamples\": resamples,\n",
    "          \"maxTrainingSizeMultiple\":maxTrainingSizeMult, # if there is more than X times more training data, trim to most recent\n",
    "          \"maxCategories\":maxCategory,\n",
    "          \"minCategoryCount\": minCategory,\n",
    "        }\n",
    "    \n",
    "    \n",
    "    # Fot fitting data right away\n",
    "    def __init__(self, dataset: pd.DataFrame, timeCol = \"date_time\",  resamples = 1000, maxTrainingSizeMult = 10, maxCategory = 100, minCategories = 10):\n",
    "        '''\n",
    "        Overloaded constructor for attaching dataset immediately, can be done independently within any of the load functions\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset: String - A pandas data frame reference\n",
    "        timeCol: String - The name of the primary TimeStamp column. Default = \"date_time\".\n",
    "        resamples: int - the number of times the bootstrap resamples. Making this very large will improve accuracy but significantly lower speed. Default = 1000\n",
    "        maxTrainingSizeMult: int - If there is more than x  = maxTrainingSizeMult ratio of training to test data, trim training data to most recent. Default = 10\n",
    "        maxCategory: int - Maximum number of categories in a column (to ensure that counts are not tiny and are meaninful), column skipped if value count higher than this. Default = 100\n",
    "        minCategory: int - if column has a category count that is lower than this value, don't report it in bootstrap surprise. Default = 10.\n",
    "        '''\n",
    "        timestamp = timeCol\n",
    "        data = dataset\n",
    "        \n",
    "        # Meta-parameter initialization\n",
    "        params = {\n",
    "          \"bootstrapResamples\": resamples,\n",
    "          \"maxTrainingSizeMultiple\":maxTrainingSizeMult, # if there is more than X times more training data, trim to most recent\n",
    "          \"maxCategories\":maxCategory,\n",
    "          \"minCategoryCount\": minCategory,\n",
    "        }\n",
    "        \n",
    "        \n",
    "    # Loading data into project\n",
    "    def load_html(self, link: str) -> pd.DataFrame():\n",
    "        '''\n",
    "        Loads an HTML table and sets it as the dataset for the model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        link: String - The link to the dataset that is being loaded\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        data : pandas.DataFrame\n",
    "            Returns the entire DataFrame that has just been loaded as the dataset for the bootstrap model\n",
    "        '''\n",
    "        self.data = pd.read_html(link)\n",
    "        return self.data\n",
    "    \n",
    "    \n",
    "    # Loading data into project\n",
    "    def load_csv(self, link: str) -> pd.DataFrame():\n",
    "        '''\n",
    "        Loads an CSV table and sets it as the dataset for the model. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        link: String - The link to the dataset that is being loaded\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        data : pandas.DataFrame\n",
    "            Returns the entire DataFrame that has just been loaded as the dataset for the bootstrap model\n",
    "        '''\n",
    "        self.data = pd.read_csv(link)\n",
    "        return self.data\n",
    "    \n",
    "    \n",
    "    #Loading data into project\n",
    "    def load_exel(self, link: str) -> pd.DataFrame():\n",
    "        '''\n",
    "        Loads an Exel table and sets it as the dataset for the model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        link: String - The link to the dataset that is being loaded\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        data : pandas.DataFrame\n",
    "            Returns the entire DataFrame that has just been loaded as the dataset for the bootstrap model\n",
    "        '''\n",
    "        self.data = pd.read_exel(link)\n",
    "        return self.data\n",
    "    \n",
    "    \n",
    "    #Loading data into project\n",
    "    def load_sql_table(self, link: str) -> pd.DataFrame():\n",
    "        '''\n",
    "        Loads a SQL table and sets it as the dataset for the model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        link: String - The link to the dataset that is being loaded\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        data : pandas.DataFrame\n",
    "            Returns the entire DataFrame that has just been loaded as the dataset for the bootstrap model\n",
    "        '''\n",
    "        self.data = pd.read_sql_table(link)\n",
    "        return self.data\n",
    "    \n",
    "    \n",
    "    # Converts Timetamp column of DataFrame to a legitimate timestamp\n",
    "    def convert_time_stamp_to_datetime(self: str, formatting = '%Y%m%d %H:%M:%S') -> pd.DataFrame:\n",
    "        '''\n",
    "        Converts a chosen timestamp column from string to date/time, making the modifications both to the fitted\n",
    "        Data Frame and returning the new Data Frame\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        timestamp: String - The name of the Timestamp column that needs conversion\n",
    "        formatting: String - If formatting different from default = %Y%m%d %H:%M:%S, enter the format of your TimeSeries column\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        data : pandas.DataFrame\n",
    "            Returns the locally the entire DataFrame with the modified Timestamp column\n",
    "        '''\n",
    "        self.data[timestamp] =  pd.to_datetime(self.data[timestamp], format = formatting)\n",
    "        return self.data\n",
    "    \n",
    "    \n",
    "    # Splits data into train and test set based on date/time\n",
    "    def split_train_test(batchHours = 24*7):\n",
    "        '''\n",
    "        Splits Data into a train and test set, held within the object\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        batchHours: int - Size of the test set in terms of hours. Default is one week (24 * 7).\n",
    "        '''\n",
    "        maxTs = max(df[timestamp])\n",
    "        batchTs = maxTs - timedelta(hours = batchHours)\n",
    "        testDf = df[df[timestamp] > batchTs]\n",
    "        trainDf = df[df[timestamp] < batchTs]\n",
    "    \n",
    "    \n",
    "    # Helpers and Math\n",
    "    def pValue(self,threshold: np.number, result) -> float:\n",
    "        # Taking the smaller of the 2 p-values(either could present large anomaly)\n",
    "        pLarger = sum(np.array(self.data) >= threshold) / len(self.data)\n",
    "        pSmaller = sum(np.array(self.data) <= threshold) / len(self.data)\n",
    "        p = min(pLarger, pSmaller)\n",
    "\n",
    "        # only use gaussian p-value when there is variation, but bootsrap p = 0\n",
    "        stdev = np.std(data)\n",
    "        if stdev == 0 or p != 0:\n",
    "            pGauss = p\n",
    "        else:\n",
    "            # Normalizing\n",
    "            pGauss = st.norm(np.mean(result['bootstrap_counts']), stdev).cdf(result['count'])\n",
    "            pGauss = min(pGauss,1-pGauss)\n",
    "        return pGauss\n",
    "\n",
    "    \n",
    "    def trimTraining(trainDf, params):\n",
    "\n",
    "        # trim to most recent\n",
    "        trainDf = trainDf.sort_values(timestamp, ascending =False)\n",
    "        trainDfTrimmed = trainDf[:params['maxTrainingSizeMultiple']*len(testDf)]\n",
    "\n",
    "        return trainDfTrimmed\n",
    "    \n",
    "    # Returns names of categorical columns\n",
    "    def getCategoricalColumnNames(df):\n",
    "        columnNames = []\n",
    "        for columnName in df.keys():\n",
    "            if (type (df[columnName].iloc[0])) == str:\n",
    "                columnNames.append(columnName)\n",
    "        return columnNames\n",
    "    \n",
    "    \n",
    "    def test(trainDf, testDf, params):\n",
    "        # get all of the string columns\n",
    "        columnNames = getCategoricalColumnNames(testDf)\n",
    "\n",
    "        bootstrapDf = trimTraining(trainDf, params)\n",
    "\n",
    "        # set up dict, add counts\n",
    "        results = {}\n",
    "\n",
    "\n",
    "        for columnName in columnNames:\n",
    "\n",
    "            # if it isn't a string column, reject it\n",
    "            if type(testDf[columnName].iloc[0]) != str:\n",
    "                continue\n",
    "            categories = (bootstrapDf[columnName].append(testDf[columnName])).unique()\n",
    "            if len(categories) > params['maxCategories']:\n",
    "                continue\n",
    "\n",
    "            results[columnName] = {}\n",
    "            testCounts = testDf[columnName].value_counts(dropna = False)\n",
    "            for i in np.arange(1,len(categories) -1):\n",
    "                if(pd.isna(categories[i])):\n",
    "                    categories = np.delete(categories, i)  \n",
    "            for category in categories:\n",
    "                results[columnName][category] = {'bootstrap_counts':[],\n",
    "\n",
    "                                                 'count':testCounts.get(category,0)}\n",
    "        # resample, add boostrap counts\n",
    "        for ii in range(params['bootstrapResamples']):\n",
    "\n",
    "            # Draw random sample from training\n",
    "            sampleDf = bootstrapDf.sample(len(testDf), replace=True)\n",
    "            for columnName in results.keys():\n",
    "\n",
    "                # count by category\n",
    "                trainCounts = sampleDf[columnName].value_counts(dropna = False)\n",
    "\n",
    "                # put results in dict\n",
    "                for category in results[columnName].keys():\n",
    "                    boostrapCount = trainCounts.get(category,0)\n",
    "                    results[columnName][category]['bootstrap_counts'].append(boostrapCount)\n",
    "\n",
    "        # convert to records, add p-values\n",
    "        bootstrap_results = []\n",
    "        for columnName in results.keys():\n",
    "            for category in results[columnName].keys():\n",
    "                result = results[columnName][category]\n",
    "\n",
    "                estimatedCount = int(np.round(np.mean(result['bootstrap_counts'])))\n",
    "\n",
    "                # don't report entries with very low predicted and actual counts\n",
    "                if estimatedCount < params['minCategoryCount'] and result['count'] < params['minCategoryCount']:\n",
    "                    continue\n",
    "\n",
    "                p = pValue(result['bootstrap_counts'],result['count'], result)\n",
    "                categoryName = category\n",
    "\n",
    "                # Backup\n",
    "                if not category:\n",
    "                    categoryName = \"NULL\"\n",
    "\n",
    "                bootstrap_results.append({\"column\":columnName,\n",
    "                                   \"category\":categoryName,\n",
    "                                   \"count\":result['count'],\n",
    "                                   \"p\": p,\n",
    "                                   \"estimated_count\":estimatedCount,\n",
    "                                   })\n",
    "\n",
    "        # Sorting by P-values and obtaining Surprise of each\n",
    "        if(np.count_nonzero(p)>0):\n",
    "            resultsDf = pd.DataFrame.from_records(bootstrap_results).sort_values('p')\n",
    "            resultsDf['surprise'] = -np.log2(resultsDf['p'])\n",
    "\n",
    "            return resultsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Utilizes facebook prophet and its ability to predict the future based off specific time context (day, hour, holiday)\n",
    "to make predictions and test those against the dataset, thus finding anomaly with the context of time\n",
    "'''\n",
    "class TimeSeries:\n",
    "    def __init__(self,x):\n",
    "        from fbprophet import Prophet\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "class KernelPCA:\n",
    "    def __init__(self,x):\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "class Kernel:\n",
    "    def __init__(self,x):\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "class PCA:\n",
    "    def __init__(self,x):\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "class Categorical:\n",
    "    def __init__(self,x):\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "class MultiDimCategorical:\n",
    "    def __init__(self,x):\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "class RunInitial:\n",
    "    def __init__(self,x):\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\"\"\"\n",
    "class Report:\n",
    "    def __init__(self,x):\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
