{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood\n",
    "### open source data quality monitor\n",
    "\n",
    "Colin Jemmott\n",
    "2020\n",
    "\n",
    "Have you ever found out an ETL job failed because a customer called?  You ever retrain a machine learning model in production just to find out the data changed out from under you?  Have a dashboard break because new data violated your assumptions?\n",
    "\n",
    "### Approach\n",
    "\n",
    "Everything is probability (or, rather [surprise](https://en.wikipedia.org/wiki/Entropy_(information_theory)#Introduction)!).  Works on a two dataframes for now - you have to get the data.\n",
    "\n",
    "Batch job, you pass in training and test.\n",
    "\n",
    "Taxonomy of problems for initial launch:\n",
    "- New values in categorical - bootstrapping\n",
    "- Missing values - bootstrapping (Nan is just another category)\n",
    "- Outliers in counts (missing or spike) - prophet\n",
    "\n",
    "To Do:\n",
    "\n",
    "- Outliers in counts of groups - bootstrapping\n",
    "- Outliers in values - kernel density?\n",
    "\n",
    "Later:\n",
    "- Outliers in correlation between categories - assocation rules / Bayesian network / just conditional probability\n",
    "- Delayed data (I think we need a writtenAt timestamp)\n",
    "- Multi-table: check joins\n",
    "- PCA?  Other anomaly detection?\n",
    "- Multitenant\n",
    "\n",
    "### Tips\n",
    "\n",
    "Some of the analysis assumes that the data is stationary (ergodic).  If that is a bad assumption it might make sense to trim history.  maxTrainingSizeMultiple controls that.\n",
    "\n",
    "### To Do\n",
    "\n",
    "- Change out data for something public (SDPD?)\n",
    "- Write params to JSON\n",
    "- preprocessor on bootsrtapping for columns with tons of entries.  Also numerical columns?\n",
    "- Throw a warning or error if the testing sample is too small?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math as mt\n",
    "import dateutil\n",
    "from datetime import datetime, timedelta\n",
    "import requests as rd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from sklearn import neighbors, decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data\n",
    "\n",
    "Not part of the actual product, but here for ease of testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "N_days = 90\n",
    "batchHours = 7*24 # this grabs the most recent chunk and looks for differences with the remainder\n",
    "\n",
    "\n",
    "# parameters (will put into JSON config file later)\n",
    "params = {\"fName\": \"pd_calls_for_service_2020_datasd.csv\", # local CSV file only right now\n",
    "          \"ts\": \"date_time\", # Timestamp for when the event happened in the world\n",
    "          \"bootstrapResamples\":1000, # should probably be 10k for better accuracy, but much worse speed\n",
    "          \"maxTrainingSizeMultiple\":10, # if there is more than X times more training data, trim to most recent\n",
    "          \"maxCategories\":100, # maximum number of categories in a column - if higher we skip\n",
    "          \"minCategoryCount\":10, # don't report boostrap surprise if a category has lower count\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data, split into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"pd_calls_for_service_2020_datasd.csv\")\n",
    "if(df.shape[0] <= 1000):\n",
    "    print(\"Warning: small data set might produce inaccurate results\")\n",
    "df['ts'] = df[params['ts']]\n",
    "print(df)\n",
    "#.apply(dateutil.parser.parse, ignoretz=True) # could speed this up for ISO8601 - currently slow.\n",
    "df['ts'] =  pd.to_datetime(df['ts'], format='%Y%m%d %H:%M:%S')\n",
    "maxTs = max(df['ts'])\n",
    "#df = df.assign(date_time = df.get(\"date_time\").apply(datetime.strptime, args = (\"%d/%m/%Y %H:%M:%S\")))\n",
    "batchTs = maxTs - timedelta(hours = batchHours)\n",
    "testDf = df[df['ts'] > batchTs]\n",
    "trainDf = df[df['ts'] < batchTs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(trainDf['ts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers and Math\n",
    "def pValue(data, threshold):\n",
    "    p_larger = sum(np.array(data) >= threshold) / len(data)\n",
    "    p_smaller = sum(np.array(data) <= threshold) / len(data)\n",
    "    p = min(p_larger, p_smaller)\n",
    "\n",
    "    # only use gaussian p-value when there is variation, but bootsrap p = 0\n",
    "    stdev = np.std(data)\n",
    "    if stdev == 0 or p != 0:\n",
    "        p_gauss = p\n",
    "    else:\n",
    "        p_gauss = scipy.stats.norm(np.mean(result['bootstrap_counts']), stdev).cdf(result['count'])\n",
    "        p_gauss = min(p_gauss,1-p_gauss)\n",
    "    return p_gauss\n",
    "\n",
    "def trimTraining(trainDf, params):\n",
    "\n",
    "    # trim to most recent\n",
    "    trainDf = trainDf.sort_values(params['ts'], ascending =False)\n",
    "    trainDfTrimmed = trainDf[:params['maxTrainingSizeMultiple']*len(testDf)]\n",
    "    \n",
    "    return trainDfTrimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all of the string columns\n",
    "columnNames = []\n",
    "for columnName in testDf.keys():\n",
    "    if (type (testDf[columnName].iloc[0])) == str:\n",
    "        columnNames.append(columnName)\n",
    "print(columnNames)\n",
    "bootstrapDf = trimTraining(trainDf, params)\n",
    "        \n",
    "# set up dict, add counts\n",
    "results = {}\n",
    "for columnName in columnNames:\n",
    "    # if it isn't a string column, reject it\n",
    "    if type(testDf[columnName].iloc[0]) != str:\n",
    "        continue\n",
    "    categories = (bootstrapDf[columnName].append(testDf[columnName])).unique()\n",
    "    if len(categories) > params['maxCategories']:\n",
    "        continue\n",
    "    \n",
    "    results[columnName] = {}\n",
    "    testCounts = testDf[columnName].value_counts(dropna = False)\n",
    "    for i in np.arange(1,len(categories) -1):\n",
    "        if(pd.isna(categories[i])):\n",
    "            categories = np.delete(categories, i)  \n",
    "    for category in categories:\n",
    "        results[columnName][category] = {'bootstrap_counts':[],\n",
    "                                        'count':testCounts.get(category,0)}\n",
    "# resample, add boostrap counts\n",
    "for ii in range(params['bootstrapResamples']):\n",
    "    # Draw random sample from training\n",
    "    sampleDf = bootstrapDf.sample(len(testDf), replace=True)\n",
    "    for columnName in results.keys():\n",
    "        # count by category\n",
    "        trainCounts = sampleDf[columnName].value_counts(dropna = False)\n",
    "        # put results in dict\n",
    "        for category in results[columnName].keys():\n",
    "            boostrapCount = trainCounts.get(category,0)\n",
    "            results[columnName][category]['bootstrap_counts'].append(boostrapCount)\n",
    "              \n",
    "# convert to records, add p-values\n",
    "bootstrap_results = []\n",
    "for columnName in results.keys():\n",
    "    for category in results[columnName].keys():\n",
    "        result = results[columnName][category]\n",
    "        \n",
    "        estimatedCount = int(np.round(np.mean(result['bootstrap_counts'])))\n",
    "        # don't report entries with very low predicted and actual counts\n",
    "        if estimatedCount < params['minCategoryCount'] and result['count'] < params['minCategoryCount']:\n",
    "            continue\n",
    "        \n",
    "        p = pValue(result['bootstrap_counts'],result['count'])\n",
    "        categoryName = category\n",
    "        if not category:\n",
    "            categoryName = \"NULL\"\n",
    "        \n",
    "        bootstrap_results.append({\"column\":columnName,\n",
    "                           \"category\":categoryName,\n",
    "                           \"count\":result['count'],\n",
    "                           \"p\": p,\n",
    "                           \"estimated_count\":estimatedCount,\n",
    "                           })\n",
    "if(np.count_nonzero(p)>0):\n",
    "    resultsDf = pd.DataFrame.from_records(bootstrap_results).sort_values('p')\n",
    "    resultsDf['surprise'] = -np.log2(resultsDf['p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsDf.head(70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timeseries forecast (prophet)\n",
    "\n",
    "Installing prophet is a major pain, especially on Windows.  Details: https://facebook.github.io/prophet/docs/installation.html\n",
    "\n",
    "Following the lead from Seismic interns: https://medium.com/seismic-data-science/anomaly-detection-using-prophet-a5dcea2c5473\n",
    "\n",
    "Decided to go hourly, but could change to day with a few tweaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncateTs(ts):\n",
    "    return ts.replace(minute=0, second=0,  microsecond=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncatedData = trainDf['ts'].apply(truncateTs)\n",
    "groupedCounts = truncatedData.value_counts()\n",
    "\n",
    "prophetDf = pd.DataFrame({'ds':groupedCounts.index,'y':np.log10(groupedCounts.values)})\n",
    "prophetDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find number of hours to preduct: ceil of hours in testDf\n",
    "timeDelta = max(testDf['ts']) -min(testDf['ts'])\n",
    "hours = int(timeDelta.days*24 + timeDelta.seconds/(60*60))+1\n",
    " \n",
    "# Train model\n",
    "m = Prophet(#daily_seasonality = True, \n",
    "            #yearly_seasonality = False, \n",
    "            #weekly_seasonality = True, \n",
    "            #growth='linear',\n",
    "            interval_width=0.68 # one sigma\n",
    "           )\n",
    "m.add_country_holidays(country_name='US')\n",
    "\n",
    "m.fit(prophetDf)\n",
    "\n",
    "future = m.make_future_dataframe(periods = hours, freq = 'H')\n",
    "fcst = m.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the test data\n",
    "truncatedData = testDf['ts'].apply(truncateTs)\n",
    "groupedCounts = truncatedData.value_counts()\n",
    "\n",
    "prophetTestDf = pd.DataFrame({'ds':groupedCounts.index,\n",
    "                              'y':np.log10(groupedCounts.values),\n",
    "                              'y_linear':groupedCounts.values})\n",
    "\n",
    "# find p-value\n",
    "prophet_results = []\n",
    "\n",
    "for ii in range(len(prophetTestDf)):\n",
    "    ts = prophetTestDf['ds'][ii]\n",
    "    fcstExample = fcst[fcst['ds'] == ts]\n",
    "    mean = fcstExample['yhat'].iloc[0]\n",
    "    stdev = (fcstExample['yhat_upper'].iloc[0] - fcstExample['yhat_lower'].iloc[0])/2\n",
    "    p = scipy.stats.norm(mean, stdev).cdf(prophetTestDf['y'][ii])\n",
    "    p = min(p,1-p)\n",
    "\n",
    "    prophet_results.append({\"column\":\"Forecast\",\n",
    "                       \"category\":str(ts),\n",
    "                       \"count\":prophetTestDf['y_linear'][ii],\n",
    "                       \"p\": p,\n",
    "                       \"estimated_count\":int(np.round(np.power(10,mean))),\n",
    "                       })\n",
    "    \n",
    "prophetResultsDf = pd.DataFrame.from_records(prophet_results).sort_values('p')\n",
    "prophetResultsDf['surprise'] = -np.log2(prophetResultsDf['p'])\n",
    "prophetResultsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting for debug only\n",
    "fig = m.plot(fcst)\n",
    "fig = m.plot_components(fcst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Density Implementation Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtaining user input\n",
    "#https://www.nbastuffer.com/2019-2020-nba-team-stats/\n",
    "def inp(default = 1, default2 = \"https://www.nbastuffer.com/2019-2020-nba-team-stats/\"):\n",
    "    if(default2 != \"https://www.nbastuffer.com/2019-2020-nba-team-stats/\"):\n",
    "        nam = input()\n",
    "    else:\n",
    "        nam = default2\n",
    "    frame = pd.read_html(nam)\n",
    "    first_table = frame[default]\n",
    "    return first_table\n",
    "first_table = inp(1,\"input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stat Computations for Formulas Found Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def getParam(default = \"PTS/GMPoints Per GameAverage points per game\"):\n",
    "    #Stuff beyond here focuses on kernel density, it is a work in progress\n",
    "    if(default != \"PTS/GMPoints Per GameAverage points per game\"):\n",
    "        print(\"Enter the column name you'd like to get a kernel density estimation for:\")\n",
    "        #Prompting user for input and calculating basic statistics, bandwidth temporarily set to .05\n",
    "        #For testing purposes\n",
    "        inp = input()\n",
    "    else:\n",
    "        inp = default\n",
    "    stat = first_table.get(inp)\n",
    "    return stat\n",
    "stat = getParam()\n",
    "#Index for purpose of making table nicer\n",
    "def getIndex(indx = \"TEAM\"):\n",
    "    if(indx!=\"TEAM\"):\n",
    "        print(\"Please enter the name of the column you'd like to serve as your index:\")\n",
    "        indx = first_table.get(input())\n",
    "    else:\n",
    "        indx = first_table.get(indx)\n",
    "    return indx\n",
    "indx = getIndex()\n",
    "\n",
    "#Plotting Data initially\n",
    "stat.plot(kind  = \"hist\")\n",
    "avg = stat.mean()\n",
    "density = np.array([])\n",
    "n = first_table.shape[0]\n",
    "dev = np.std(stat)\n",
    "\n",
    "kernelEstimations = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kernel Estimation for a Gaussian, Cosine, Triangular, and Parabolic Kernel are found below, metric used for surprise computation will be based on their average. Idea is: if between them we can found a standard density, we can find values that are more likely to be outliers. Other idea: find outliers for every one and check for commonalities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit learn citation because their software is utilized\n",
    "@article{scikit-learn,\n",
    " title={Scikit-learn: Machine Learning in {P}ython},\n",
    " author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.\n",
    "         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.\n",
    "         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and\n",
    "         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},\n",
    " journal={Journal of Machine Learning Research},\n",
    " volume={12},\n",
    " pages={2825--2830},\n",
    " year={2011}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using cosine kernel function to get estimate for log density\n",
    "def cosKernel(stat):\n",
    "    stat = stat.to_numpy().reshape(-1,1) \n",
    "    l = neighbors.KernelDensity(kernel = 'cosine').fit(stat)\n",
    "    cos_density = l.score_samples(stat)\n",
    "    return cos_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using gaussian kernel function to get estimate for log density\n",
    "def gaussKernel(stat):\n",
    "    stat = stat.to_numpy().reshape(-1,1) \n",
    "    l = neighbors.KernelDensity(kernel = 'gaussian').fit(stat)\n",
    "    density = l.score_samples(stat)\n",
    "    return density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using linear kernel function to get estimate for log density\n",
    "def expKernel(stat):\n",
    "    stat = stat.to_numpy().reshape(-1,1) \n",
    "    l = neighbors.KernelDensity(kernel = 'exponential').fit(stat)\n",
    "    triDensity = l.score_samples(stat)\n",
    "    return triDensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converted to Proportion for u < 1 supported functions\n",
    "def toProp(number):\n",
    "    return number/max(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using epanechnikov kernel function to get estimate for log density\n",
    "def parabolicKernel(stat):\n",
    "    stat = stat.to_numpy().reshape(-1,1) \n",
    "    l = neighbors.KernelDensity(kernel = 'epanechnikov').fit(stat)\n",
    "    epDensity = l.score_samples(stat)\n",
    "    return epDensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates normal distribution (we have standardized data) and calculates P-value with the null hypothesis being no systematic error\n",
    "def retPVal(col):\n",
    "    #Since we have a normal distribution, starting by obtaining the z-score\n",
    "    mean = col.mean()\n",
    "    std = np.std(col)\n",
    "    array = np.array([])\n",
    "    for i in np.arange(len(col)):\n",
    "        array = np.append(array, col.iloc[i] - mean)\n",
    "    \n",
    "    #Now obtaining legitimate p-values\n",
    "    z_scores = array/std\n",
    "    for l in np.arange(len(z_scores)):\n",
    "        cdf = st.norm.cdf(z_scores[l])\n",
    "        z_scores[l] = min(cdf, 1-cdf)\n",
    "    return pd.Series(z_scores, index = col.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Values Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning initial kernal estimations\n",
    "def kernelEstimator(indx, stat):\n",
    "    kernelEstimate = pd.DataFrame()\n",
    "    kernelEstimate = kernelEstimate.assign(Data_Index = indx, Data_Point = stat,Gaussian = gaussKernel(stat),\n",
    "                                               Epanechnikov = parabolicKernel(stat), Exponential = expKernel(stat),\n",
    "                                               Cosine = cosKernel(stat))\n",
    "    # temporary sort for some visualization of surprise\n",
    "    kernelEstimate = kernelEstimate.sort_values(by = \"Gaussian\", ascending = False)\n",
    "    return kernelEstimate\n",
    "kernelEstimation = kernelEstimator(indx, stat)\n",
    "kernelEstimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating their average\n",
    "def surprise_estimator(kernelEstimation):\n",
    "    numDevMax = (kernelEstimation.get(\"Data_Point\").max() - kernelEstimation.get(\"Data_Point\").mean())/kernelEstimation.get(\"Data_Point\").std()\n",
    "    numDevMin = (kernelEstimation.get(\"Data_Point\").min() - kernelEstimation.get(\"Data_Point\").mean())/kernelEstimation.get(\"Data_Point\").std()\n",
    "    numDev = max(numDevMax, numDevMin)\n",
    "    if(numDev > 3.2):\n",
    "        metric = retPVal(kernelEstimation.get(\"Exponential\"))\n",
    "    elif((numDev <=3.2) & (numDev >= 2)):\n",
    "        metric = retPVal(kernelEstimation.get(\"Gaussian\"))\n",
    "    else:\n",
    "        metric = retPVal(kernelEstimation.get(\"Exponential\")+kernelEstimation.get(\"Epanechnikov\"))          \n",
    "    # Surprise Metric\n",
    "    kernelEstimation  = kernelEstimation.assign(Surprise = -np.log2(metric))\n",
    "    kernelEstimation = kernelEstimation.sort_values(by = \"Surprise\", ascending = False)\n",
    "    return kernelEstimation\n",
    "kernelEstimation = surprise_estimator(kernelEstimation)\n",
    "kernelEstimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A grouping of the entire kernel estimation process\n",
    "def surprise_Table(Table, index = \"TEAM\"):\n",
    "    temp = pcaPrep(Table)\n",
    "    if(isinstance(index, str)):\n",
    "        index = Table.get(index)\n",
    "    sum_surprise  = pd.Series(np.zeros(Table.shape[0]))\n",
    "    for col in temp.columns:\n",
    "        stat = temp.get(col)\n",
    "        KernelTable = kernelEstimator(index, stat)\n",
    "        KernelTable = surprise_estimator(KernelTable)\n",
    "        Table[col] = KernelTable.get(\"Surprise\")\n",
    "        sum_surprise+=Table[col]\n",
    "    sum_surprise = sum_surprise.array\n",
    "    if(not isinstance(index, str)):\n",
    "        Table = Table.set_index(index)\n",
    "    Table = Table.assign(mean_surprise = np.round(sum_surprise/Table.shape[1],2))\n",
    "    # Sorting table for easier visualization\n",
    "    Table = Table.sort_values(by = \"mean_surprise\", ascending  = False)\n",
    "    return Table\n",
    "modTable = first_table\n",
    "surpriseTable = surprise_Table(first_table)\n",
    "surpriseTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Exponential Density should apply to a more fat-tailed distribution, and makes less assumption of outliers, others assume a less spread out (parabolic and cosine) or normal (gaussian) distribution. To truly quantify an outlier, exponential density should be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surpriseTable.plot(kind = \"barh\", y = \"mean_surprise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surpriseTable.get(\"mean_surprise\").plot(kind = \"hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA and Singular Value Decomp for Cross Column Correlation Lie Ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import smtplib\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader(first_table):\n",
    "    # Giving user option to change dataset\n",
    "    print(\"Would you like to change the data set you are working with?\")\n",
    "    if(input().upper() == \"YES\"):\n",
    "        print(\"Enter the URL below:\")\n",
    "        nam = input()\n",
    "        frame = pd.read_html(nam)\n",
    "        table = frame[1]\n",
    "        return table\n",
    "    else:\n",
    "        return first_table\n",
    "first_table = loader(first_table)\n",
    "print(\"\\ndataset below:\")\n",
    "first_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pcaPrep(first_table):\n",
    "# Finding all numerical components of the table so that pca can function\n",
    "    tabl = first_table.select_dtypes(include = [np.number])\n",
    "    tabl = tabl.dropna(1)\n",
    "    return tabl\n",
    "\n",
    "def obtain_variance_table(first_table):\n",
    "    tabl = pcaPrep(first_table)\n",
    "    scaled_data = StandardScaler().fit_transform(tabl)\n",
    "    # Creating a PCA object \n",
    "    pca = PCA(n_components = (tabl.shape[1]))\n",
    "    pcaData = pca.fit_transform(scaled_data)\n",
    "    infoFrame = pd.DataFrame().assign(Column = [\"PC\" + str(i) for i in range(tabl.shape[1])], Variance_ratio = pca.explained_variance_ratio_ )\n",
    "    return infoFrame\n",
    "obtain_variance_table(first_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtainPCAVals(componentNum, scaled_data):\n",
    "    pca = PCA(n_components = componentNum)\n",
    "    print(scaled_data)\n",
    "    pcaData = pca.fit_transform(scaled_data)\n",
    "    return pcaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deciding how many columns need to be used: utilizing threashold of 95% of the explained variance\n",
    "def elementDecider(infoFrame):\n",
    "    numSum = 0\n",
    "    counter = 0\n",
    "    for i in infoFrame.get(\"Variance_ratio\"):\n",
    "        if(numSum < .95):\n",
    "            numSum += i\n",
    "            counter+=1\n",
    "    return counter\n",
    "\n",
    "#Reducing dimensionality of data into pc's, only storing what is neccessary\n",
    "def reducedData(infoFrame,  scaled_data, indx):\n",
    "    numCols = elementDecider(infoFrame)\n",
    "    pcaData = obtainPCAVals(numCols, scaled_data)\n",
    "    pcaFrame = pd.DataFrame(pcaData)\n",
    "    if(not isinstance(indx, str)):\n",
    "        pcaFrame = pcaFrame.set_index(indx)\n",
    "    return pcaFrame\n",
    "\n",
    "#Visualization tool for seeing grouping of elements by pc\n",
    "def displayReducedData(pcaVals, xNum = 0, yNum = 1):\n",
    "    # Ensuring that the elements given do not overacess table \n",
    "    if(xNum < pcaVals.shape[1]) & (yNum < pcaVals.shape[1]):\n",
    "        pcaVals.plot(kind = \"scatter\", x = 2, y = 3)\n",
    "    else:\n",
    "        print(\"You have overaccessed the number of elements, keep in mind there are only \" + str(pcaVals.shape[1]) + \" elements\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summing p-values because PCA serves to check for systematic bias, whereas kernel density checks for accuracy\n",
    "def sumRows(pcaVals):\n",
    "    sumArray = np.zeros(pcaVals.shape[0])\n",
    "    for i in np.arange(pcaVals.shape[1]):\n",
    "        values = pcaVals.get(str(i)).array\n",
    "        sumArray += values\n",
    "    sumArray /= pcaVals.shape[1]\n",
    "    #After obtaining sum, the average deviation from the expected value is averaged out, not taking in absolute value\n",
    "    # to check for systematic error\n",
    "    return sumArray\n",
    "\n",
    "    \n",
    "def pcaRowOutliers(pcaVals):\n",
    "    P_val_table = pd.DataFrame()\n",
    "    #Creating a table of all the PCA p-values\n",
    "    for col in np.arange(0,pcaVals.shape[1]):\n",
    "        P_vals =  retPVal(pcaVals.get(col))\n",
    "        i = str(col)\n",
    "        P_val_table[i] = P_vals\n",
    "    print(\"The P-Values of each PCA score found below: \\n\")\n",
    "    print(P_val_table)\n",
    "    totalVar = sumRows(P_val_table)\n",
    "    \n",
    "    #Calculating surprise by taking negative log\n",
    "    newVals = pcaVals.assign(Surprise = -np.log2(totalVar))\n",
    "    newVals = newVals.sort_values(by = \"Surprise\", ascending = False)\n",
    "    return newVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runPCA(table, index):\n",
    "    processing_table = pcaPrep(table)\n",
    "    variance_table = obtain_variance_table(table)\n",
    "    pcaVals = reducedData(variance_table, StandardScaler().fit_transform(processing_table), table.get(index))\n",
    "    new_pca = pcaRowOutliers(pcaVals)\n",
    "    return new_pca\n",
    "new_pca = runPCA(first_table, 'TEAM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have found individual outliers with both a column approach and a row-based approach, we group the 2 approaches using naive bayes in a manner that is easy to read. Idea: group by sum of surprise so outliers appear at the top!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_kernel_combo(pcaTable,kernelTable):\n",
    "    pcaSurpriseCol = new_pca.get(\"Surprise\")\n",
    "    temp = pcaPrep(kernelTable)\n",
    "    for column in temp.columns:\n",
    "        kernelTable[column] = (kernelTable[column].multiply(pcaSurpriseCol)).apply(np.sqrt)\n",
    "    kernelTable = kernelTable.sort_values(by = \"mean_surprise\", ascending = False)\n",
    "    return kernelTable\n",
    "surpriseTable = pca_kernel_combo(new_pca, surpriseTable) \n",
    "surpriseTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attaching Program to Data Set Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.read_csv(\"http://seshat.datasd.org/budget/budget_operating_datasd.csv\", nrows = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      amount  report_fy budget_cycle     fund_type  fund_number  \\\n",
      "0   379363.0         17      adopted  General Fund       100000   \n",
      "1   139001.0         17      adopted  General Fund       100000   \n",
      "2     7650.0         17      adopted  General Fund       100000   \n",
      "3     7778.0         17      adopted  General Fund       100000   \n",
      "4     7650.0         17      adopted  General Fund       100000   \n",
      "5     3646.0         17      adopted  General Fund       100000   \n",
      "6    36109.0         17      adopted  General Fund       100000   \n",
      "7     3066.0         17      adopted  General Fund       100000   \n",
      "8     1207.0         17      adopted  General Fund       100000   \n",
      "9      690.0         17      adopted  General Fund       100000   \n",
      "10    5501.0         17      adopted  General Fund       100000   \n",
      "11   17745.0         17      adopted  General Fund       100000   \n",
      "12     310.0         17      adopted  General Fund       100000   \n",
      "13   11441.0         17      adopted  General Fund       100000   \n",
      "14    2000.0         17      adopted  General Fund       100000   \n",
      "15     200.0         17      adopted  General Fund       100000   \n",
      "16    1000.0         17      adopted  General Fund       100000   \n",
      "17     800.0         17      adopted  General Fund       100000   \n",
      "18    1000.0         17      adopted  General Fund       100000   \n",
      "19     500.0         17      adopted  General Fund       100000   \n",
      "20     500.0         17      adopted  General Fund       100000   \n",
      "21   15438.0         17      adopted  General Fund       100000   \n",
      "22     750.0         17      adopted  General Fund       100000   \n",
      "23    6000.0         17      adopted  General Fund       100000   \n",
      "24   20000.0         17      adopted  General Fund       100000   \n",
      "25     500.0         17      adopted  General Fund       100000   \n",
      "26    1000.0         17      adopted  General Fund       100000   \n",
      "27    1500.0         17      adopted  General Fund       100000   \n",
      "28     763.0         17      adopted  General Fund       100000   \n",
      "29    8289.0         17      adopted  General Fund       100000   \n",
      "..       ...        ...          ...           ...          ...   \n",
      "39     279.0         17      adopted  General Fund       100000   \n",
      "40    9600.0         17      adopted  General Fund       100000   \n",
      "41     766.0         17      adopted  General Fund       100000   \n",
      "42  171032.0         17      adopted  General Fund       100000   \n",
      "43   38449.0         17      adopted  General Fund       100000   \n",
      "44    1074.0         17      adopted  General Fund       100000   \n",
      "45   93229.0         17      adopted  General Fund       100000   \n",
      "46    5131.0         17      adopted  General Fund       100000   \n",
      "47    5217.0         17      adopted  General Fund       100000   \n",
      "48     580.0         17      adopted  General Fund       100000   \n",
      "49    3390.0         17      adopted  General Fund       100000   \n",
      "50    1164.0         17      adopted  General Fund       100000   \n",
      "51   24581.0         17      adopted  General Fund       100000   \n",
      "52    2044.0         17      adopted  General Fund       100000   \n",
      "53     666.0         17      adopted  General Fund       100000   \n",
      "54     382.0         17      adopted  General Fund       100000   \n",
      "55    3037.0         17      adopted  General Fund       100000   \n",
      "56   11830.0         17      adopted  General Fund       100000   \n",
      "57    1442.0         17      adopted  General Fund       100000   \n",
      "58     210.0         17      adopted  General Fund       100000   \n",
      "59     510.0         17      adopted  General Fund       100000   \n",
      "60     410.0         17      adopted  General Fund       100000   \n",
      "61     612.0         17      adopted  General Fund       100000   \n",
      "62     202.0         17      adopted  General Fund       100000   \n",
      "63     667.0         17      adopted  General Fund       100000   \n",
      "64  663927.0         17      adopted  General Fund       100000   \n",
      "65    1419.0         17      adopted  General Fund       100000   \n",
      "66   80105.0         17      adopted  General Fund       100000   \n",
      "67  166276.0         17      adopted  General Fund       100000   \n",
      "68   11412.0         17      adopted  General Fund       100000   \n",
      "\n",
      "                                dept_name  funds_center_number  \\\n",
      "0   Office of the Chief Operating Officer           1001000011   \n",
      "1   Office of the Chief Operating Officer           1001000011   \n",
      "2   Office of the Chief Operating Officer           1001000011   \n",
      "3   Office of the Chief Operating Officer           1001000011   \n",
      "4   Office of the Chief Operating Officer           1001000011   \n",
      "5   Office of the Chief Operating Officer           1001000011   \n",
      "6   Office of the Chief Operating Officer           1001000011   \n",
      "7   Office of the Chief Operating Officer           1001000011   \n",
      "8   Office of the Chief Operating Officer           1001000011   \n",
      "9   Office of the Chief Operating Officer           1001000011   \n",
      "10  Office of the Chief Operating Officer           1001000011   \n",
      "11  Office of the Chief Operating Officer           1001000011   \n",
      "12  Office of the Chief Operating Officer           1001000011   \n",
      "13  Office of the Chief Operating Officer           1001000011   \n",
      "14  Office of the Chief Operating Officer           1001000011   \n",
      "15  Office of the Chief Operating Officer           1001000011   \n",
      "16  Office of the Chief Operating Officer           1001000011   \n",
      "17  Office of the Chief Operating Officer           1001000011   \n",
      "18  Office of the Chief Operating Officer           1001000011   \n",
      "19  Office of the Chief Operating Officer           1001000011   \n",
      "20  Office of the Chief Operating Officer           1001000011   \n",
      "21  Office of the Chief Operating Officer           1001000011   \n",
      "22  Office of the Chief Operating Officer           1001000011   \n",
      "23  Office of the Chief Operating Officer           1001000011   \n",
      "24  Office of the Chief Operating Officer           1001000011   \n",
      "25  Office of the Chief Operating Officer           1001000011   \n",
      "26  Office of the Chief Operating Officer           1001000011   \n",
      "27  Office of the Chief Operating Officer           1001000011   \n",
      "28  Office of the Chief Operating Officer           1001000011   \n",
      "29  Office of the Chief Operating Officer           1001000011   \n",
      "..                                    ...                  ...   \n",
      "39  Office of the Chief Operating Officer           1001000011   \n",
      "40  Office of the Chief Operating Officer           1001000011   \n",
      "41  Office of the Chief Operating Officer           1001000011   \n",
      "42  Office of the Chief Operating Officer           1001001111   \n",
      "43  Office of the Chief Operating Officer           1001001111   \n",
      "44  Office of the Chief Operating Officer           1001001111   \n",
      "45  Office of the Chief Operating Officer           1001001111   \n",
      "46  Office of the Chief Operating Officer           1001001111   \n",
      "47  Office of the Chief Operating Officer           1001001111   \n",
      "48  Office of the Chief Operating Officer           1001001111   \n",
      "49  Office of the Chief Operating Officer           1001001111   \n",
      "50  Office of the Chief Operating Officer           1001001111   \n",
      "51  Office of the Chief Operating Officer           1001001111   \n",
      "52  Office of the Chief Operating Officer           1001001111   \n",
      "53  Office of the Chief Operating Officer           1001001111   \n",
      "54  Office of the Chief Operating Officer           1001001111   \n",
      "55  Office of the Chief Operating Officer           1001001111   \n",
      "56  Office of the Chief Operating Officer           1001001111   \n",
      "57  Office of the Chief Operating Officer           1001001111   \n",
      "58  Office of the Chief Operating Officer           1001001111   \n",
      "59  Office of the Chief Operating Officer           1001001111   \n",
      "60  Office of the Chief Operating Officer           1001001111   \n",
      "61  Office of the Chief Operating Officer           1001001111   \n",
      "62  Office of the Chief Operating Officer           1001001111   \n",
      "63  Office of the Chief Operating Officer           1001001111   \n",
      "64                     Council District 1           1101000001   \n",
      "65                     Council District 1           1101000001   \n",
      "66                     Council District 1           1101000001   \n",
      "67                     Council District 1           1101000001   \n",
      "68                     Council District 1           1101000001   \n",
      "\n",
      "                                     account  account_number  \n",
      "0                             Salaried Wages          500011  \n",
      "1                  CERS - General Retirement          502012  \n",
      "2               Supp Pens Sav Plan Mandatory          502021  \n",
      "3               Supp Pens Sav Plan Voluntary          502022  \n",
      "4            CERS-UAAL Unclass-Unrepresented          502043  \n",
      "5                    Workers' Comp Insurance          502046  \n",
      "6                      Flexible Benefit Plan          502047  \n",
      "7                   Risk Mgmt Administration          502048  \n",
      "8                       Long Term Disability          502049  \n",
      "9                     Unemployment Insurance          502050  \n",
      "10                   Fica/Medicare Insurance          502051  \n",
      "11               Retiree Health Contribution          502052  \n",
      "12                      Employer Contrib RMT          502077  \n",
      "13                    SPSP-H General Members          502094  \n",
      "14                           Office Supplies          511010  \n",
      "15                           Postage/Mailing          511011  \n",
      "16                      Computer Accessories          511048  \n",
      "17                              Copier Paper          511117  \n",
      "18           1 Day Trips-Less Than 200 Miles          512000  \n",
      "19                           Fees-Membership          512043  \n",
      "20             Meals With Non-City Employees          512057  \n",
      "21  Miscellaneous Professional/Technical Ser          512059  \n",
      "22                            Parking Stamps          512064  \n",
      "23                          Training-In Town          512070  \n",
      "24                       Travel-Non Training          512072  \n",
      "25                           Travel-Training          512073  \n",
      "26                        Photocopy Services          512077  \n",
      "27                       Print Shop Services          512080  \n",
      "28          Interfund Environmental Services          512108  \n",
      "29                    SAP Support Allocation          512162  \n",
      "..                                       ...             ...  \n",
      "39           Wireless Communication Transfer          514112  \n",
      "40                  Transportation Allowance          516015  \n",
      "41  Information Technology Services Transfer          516021  \n",
      "42                            Salaried Wages          500011  \n",
      "43                              Hourly Wages          500121  \n",
      "44                       Sick Leave - Hourly          500134  \n",
      "45                 CERS - General Retirement          502012  \n",
      "46              Supp Pens Sav Plan Mandatory          502021  \n",
      "47              Supp Pens Sav Plan Voluntary          502022  \n",
      "48                 CERS-UAAL MEA Supervisory          502039  \n",
      "49        CERS-UAAL Classified Unrepresented          502042  \n",
      "50                   Workers' Comp Insurance          502046  \n",
      "51                     Flexible Benefit Plan          502047  \n",
      "52                  Risk Mgmt Administration          502048  \n",
      "53                      Long Term Disability          502049  \n",
      "54                    Unemployment Insurance          502050  \n",
      "55                   Fica/Medicare Insurance          502051  \n",
      "56               Retiree Health Contribution          502052  \n",
      "57                           SPSP-H Budgeted          502073  \n",
      "58                           Office Supplies          511010  \n",
      "59                           Postage/Mailing          511011  \n",
      "60                        Photocopy Services          512077  \n",
      "61                          Wireless Stipend          512245  \n",
      "62            Network Access - Discretionary          513004  \n",
      "63                        Voice/Data Network          513212  \n",
      "64                            Salaried Wages          500011  \n",
      "65                       Sick Leave - Hourly          500134  \n",
      "66                 CERS - Legislative Retire          502010  \n",
      "67                 CERS - General Retirement          502012  \n",
      "68              Supp Pens Sav Plan Mandatory          502021  \n",
      "\n",
      "[69 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(table.head(69))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = (table.groupby(\"account_number\").mean()).reset_index()\n",
    "print(table)\n",
    "def main(table):\n",
    "    kernelTable = surprise_Table(table, 10)\n",
    "    pcaTable = runPCA(table, table.get(\"account_number\"))\n",
    "    combo = pca_kernel_combo(pcaTable, kernelTable)\n",
    "    return designer(combo)\n",
    "main(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import schedule\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule.every().friday.do(main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tackling the Categorical Question Below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are several categorical questions that could be tackled with this program, ultimately, this will be used in the report which assesses flaws in the data. I perceive the functionality to work something like a data spellcheck. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This attempts to answer the questions above but with categorical data: is there a problem and if so where is it? However it is different in that this will also attempt to answer why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program will be built upon the principals of entropy and will work something like this: languages have a structure and rules. There is a certain grammar to be followed, and the more strict the grammar is the lower a systems relative entropy (its entropy relative to the maximum entropy that could be had). Thus, more structure  = stricter interpretation of the data and outliers. If something follows the rule, it airs on the side of redundancy. Otherwise, it airs on the side of the entropy of the rule. Thus, the easiest approach to finding a numerical outlier within data is to build rules that are as abstract and all encompassing as possible (so as to avoid the need for context), and obtain the entropy of every data point in regards to whether it does/ does not follow the rules. Naturally, the data which does not follow the rules is bound to have greater entropy, but particularly if the rule is strict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if the data set is terribly structured and the data frequently breaks rules then it is not at all surprising for a rule to be broken. If, say, every bit of data broke an entirely different rule once (the most extreme case of a dataset having a massive total entropy), it would be not at all surprising to see data break rules. Thus, the surprise will be measured as a true metric of relative entropy, meaning that we are measuring the anomaly of all the rules a piece of data broke: relative to how often and severly rules are broken. This will put things in better context. The why piece of the question after measuring this should be easy: for each piece of data, the program will store which rules the data broke: and how strict these rules were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein as leven\n",
    "from pandas.api.types import is_numeric_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any numeric Columns you would consider categorical?(yes/no)\n",
      "no\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['budget_cycle', 'fund_type', 'dept_name', 'account']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Will examine whether or not a column is categorical, giving the user the opportunity to add additional numeric columns\n",
    "def identifyCategorical(surpriseFrame):\n",
    "    categorical_list = []\n",
    "    for col in surpriseFrame.columns:\n",
    "        if(not(is_numeric_dtype(surpriseFrame[col]))):\n",
    "            categorical_list.append(col)\n",
    "    \n",
    "    # Allows fixing of default assumption that numeric columns aren't categorical\n",
    "    print(\"Are there any numeric Columns you would consider categorical?(yes/no)\")\n",
    "    while(input().upper() == \"YES\"):\n",
    "        print(\"Enter one such column:\")\n",
    "        categorical_list.append(input())\n",
    "        print(\"Any more?\")\n",
    "    return categorical_list\n",
    "\n",
    "# We want to preserve initial NaN's, so passing first_table instead of modified surpriseTable\n",
    "categorical_columns = identifyCategorical(table)\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is categorical approach, which has been updated so some remnants of previous code might remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any numeric Columns you would consider categorical?\n",
      "no\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_unique_ratio</th>\n",
       "      <th>number_unique_values</th>\n",
       "      <th>nan_ratio</th>\n",
       "      <th>based_off_sample</th>\n",
       "      <th>num_html_tags</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categorical_columns</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>budget_cycle</th>\n",
       "      <td>0.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fund_type</th>\n",
       "      <td>0.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dept_name</th>\n",
       "      <td>0.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>account</th>\n",
       "      <td>0.92</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     column_unique_ratio  number_unique_values  nan_ratio  \\\n",
       "categorical_columns                                                         \n",
       "budget_cycle                        0.02                   1.0        0.0   \n",
       "fund_type                           0.02                   1.0        0.0   \n",
       "dept_name                           0.02                   1.0        0.0   \n",
       "account                             0.92                  46.0        0.0   \n",
       "\n",
       "                     based_off_sample  num_html_tags  \n",
       "categorical_columns                                   \n",
       "budget_cycle                     50.0            0.0  \n",
       "fund_type                        50.0            0.0  \n",
       "dept_name                        50.0            0.0  \n",
       "account                          50.0            0.0  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determines uniqueness ratios to determine whether a unique/nonunique value is an anomaly\n",
    "#Returns ratios for metaData data frame in next method\n",
    "def unique_ratio(surpriseFrame, categorical_columns):\n",
    "    ratios = np.array([])\n",
    "    \n",
    "    # Removing NaN's because they can be treated as 0 for this purpose, this way we can identify them as a non-unique value\n",
    "    surpriseFrame = surpriseFrame.replace({np.nan:0})\n",
    "    for column in categorical_columns:\n",
    "        ratios = np.append(ratios, len(np.unique(surpriseFrame.get(column).to_numpy()))/ surpriseFrame.shape[0])   \n",
    "    return ratios\n",
    "\n",
    "#Obtaining sample size for sake of metadata comparisons and possible p-value calculation PER sample size\n",
    "def sampleSizeArray(table, categorical_columns):\n",
    "    array = np.array([])\n",
    "    for i in categorical_columns:\n",
    "        array = np.append(array, table.shape[0])\n",
    "    return array\n",
    "\n",
    "# Builds DataFrame full of metadata off of given training set that is to be used for later comparisons\n",
    "def metaData(table):\n",
    "        metadata_table = pd.DataFrame()\n",
    "        categorical_cols = identifyCategorical(table)\n",
    "        uniqueness = unique_ratio(table, categorical_cols)\n",
    "        \n",
    "        # Number and ratio of unique values to be used for detection of anomalies in the appearance of new values\n",
    "        metadata_table = metadata_table.assign(categorical_columns = categorical_cols, column_unique_ratio = uniqueness)\n",
    "        metadata_table = metadata_table.assign(number_unique_values = np.round(uniqueness*table.shape[0]))\n",
    "        metadata_table = metadata_table.assign(nan_ratio = nan_ratio(table, categorical_cols)).set_index(\"categorical_columns\")\n",
    "        \n",
    "        #obtaining sample size, number of html tags\n",
    "        metadata_table = metadata_table.assign(based_off_sample = sampleSizeArray(table, categorical_cols) )\n",
    "        metadata_table = metadata_table.assign(num_html_tags = contains_HTML(table, categorical_cols))\n",
    "        return metadata_table\n",
    "metadata1 = metaData(table.head(50))\n",
    "metadata1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating anomaly for classification: type, whether it is an nan, and the length of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns suprise of type classification\n",
    "def types(column):\n",
    "    value_types = column.apply(classifier)\n",
    "    counts  = value_types.value_counts(normalize = True)\n",
    "    print(counts)\n",
    "    index = counts.index\n",
    "    values = counts.values\n",
    "    probs = value_types.apply(giveProb, args = (np.array(index), np.array(values)))\n",
    "    surpriseVal = probs.apply(surprise)\n",
    "    return surpriseVal\n",
    "\n",
    "# Obtains the type of value, even if it is currently contained within a string\n",
    "def classifier(value):\n",
    "    value = str(value)\n",
    "    # Boolean check done manually: this is an easy check\n",
    "    if(('True' in value) or ('False' in value )):\n",
    "        return 'boolean'\n",
    "    else:\n",
    "        if(value.isnumeric()):\n",
    "            return 'number'\n",
    "        else:\n",
    "            return 'string'\n",
    "    \n",
    "# Takes in a column and returns the surprise of each nan value being present (True) or not being present (False)\n",
    "def nans(column):\n",
    "    nan_values = column.apply(isNan)\n",
    "    counts  = nan_values.value_counts(normalize = True)\n",
    "    index = counts.index\n",
    "    values = counts.values\n",
    "    probs = nan_values.apply(giveProb, args = (np.array(index), np.array(values)))\n",
    "    surpriseVal = probs.apply(surprise)\n",
    "    return surpriseVal\n",
    "\n",
    "# Takes in a column and returns the surprise of the length of each value in the column: the first and simplest of probabilistic tests\n",
    "def lenCount(column):\n",
    "    column = column.apply(str)\n",
    "    counts = column.apply(len).value_counts(normalize = True)\n",
    "    index = counts.index\n",
    "    values = counts.values\n",
    "    column = column.apply(len)\n",
    "    probs = column.apply(giveProb, args = (np.array(index), np.array(values)))\n",
    "    surpriseVal = probs.apply(surprise)\n",
    "    return surpriseVal\n",
    "\n",
    "# Calculates the surprise of a given value\n",
    "def surprise(value):\n",
    "    return -np.log2(value)\n",
    "\n",
    "# Given a numerical value, finds it equivalent within the set of indices and assigns it the proper probability\n",
    "def giveProb(value, index, values):\n",
    "    for num in np.arange(len(index)):\n",
    "        if(value == index[num]):\n",
    "            return values[num]\n",
    "    return values[0]\n",
    "        \n",
    "\n",
    "# NaN's aren't equal to themselves\n",
    "def isNan(x):\n",
    "    return x!=x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following part deals with structure: uniqueness and special characters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks for special characters within a string, calculating surprise so as to identify which character combinations are chaotic\n",
    "def special_char(column):\n",
    "    characters = column.apply(str).apply(char_identifier)\n",
    "    counts  = characters.value_counts(normalize = True)\n",
    "    index = counts.index\n",
    "    values = counts.values\n",
    "    probs = characters.apply(giveProb, args = (np.array(index), np.array(values)))\n",
    "    surpriseVal = probs.apply(surprise)\n",
    "    return surpriseVal\n",
    "\n",
    "# Checks if a single entry of any data type contains special symbols and returns all that it contains\n",
    "def char_identifier(entry):\n",
    "    charList = np.array(['<', '>', '!', '#','_','@','$','&','*','^', ' ', '/', '-','\"','(', ',', ')', '?', '.'])\n",
    "    ret_string = \"\"\n",
    "    for i in charList:\n",
    "        if(i in entry):\n",
    "            ret_string += i\n",
    "    return ret_string\n",
    "\n",
    "# Simpler approach here: if the value counts of certain elements are greater when they should be unique, they are more suprising\n",
    "# If they are non-unique when they are supposed to be unique, also more surprising. Done with binary classification\n",
    "def uniques(column):\n",
    "    # Counting number of each value and returning whether or not it is a singular unique value,\n",
    "    #then counting truly unique values\n",
    "    vals = column.value_counts().apply(isunique)\n",
    "    counts = vals.value_counts(normalize = True)\n",
    "    index = counts.index\n",
    "    values = counts.values\n",
    "    probs = vals.apply(giveProb, args = (np.array(index), np.array(values)))\n",
    "    surpriseVal = probs.apply(surprise)\n",
    "    # Note: if all values unique/non unique this will provide definite outcome because no room for uncertainty\n",
    "    return surpriseVal\n",
    "\n",
    "# Returns whether the count of a value is 1\n",
    "def isunique(val):\n",
    "    return (val == 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conducting unit tests that examine type and severity of the issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any numeric Columns you would consider categorical?\n",
      "no\n",
      "['ordinary' 'ordinary' 'ordinary' 'ordinary']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_value_status</th>\n",
       "      <th>html_tag_status</th>\n",
       "      <th>nan_status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categorical_columns</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>budget_cycle</th>\n",
       "      <td>ordinary</td>\n",
       "      <td>ordinary</td>\n",
       "      <td>ordinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fund_type</th>\n",
       "      <td>ordinary</td>\n",
       "      <td>ordinary</td>\n",
       "      <td>ordinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dept_name</th>\n",
       "      <td>problems: 11.0, new unique values(ratio normal)</td>\n",
       "      <td>ordinary</td>\n",
       "      <td>ordinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>account</th>\n",
       "      <td>problems: 26.0, new unique values(ratio not no...</td>\n",
       "      <td>ordinary</td>\n",
       "      <td>ordinary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   unique_value_status  \\\n",
       "categorical_columns                                                      \n",
       "budget_cycle                                                  ordinary   \n",
       "fund_type                                                     ordinary   \n",
       "dept_name              problems: 11.0, new unique values(ratio normal)   \n",
       "account              problems: 26.0, new unique values(ratio not no...   \n",
       "\n",
       "                    html_tag_status nan_status  \n",
       "categorical_columns                             \n",
       "budget_cycle               ordinary   ordinary  \n",
       "fund_type                  ordinary   ordinary  \n",
       "dept_name                  ordinary   ordinary  \n",
       "account                    ordinary   ordinary  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tests for all potential issues, returns issue + severity\n",
    "# Idea: should user be able to disable default tests?\n",
    "def metadata_tester(metadata1, chosen_data):\n",
    "    problem_meta = pd.DataFrame()\n",
    "    metadata2 = metaData(chosen_data)\n",
    "    problem_meta = problem_meta.assign(unique_value_status = unique_values_test(metadata1, metadata2)).set_index(metadata1.index)\n",
    "    problem_meta = problem_meta.assign(html_tag_status = html_test(metadata1, metadata2))\n",
    "    problem_meta = problem_meta.assign(nan_status = nan_test(metadata1, metadata2))\n",
    "    return problem_meta\n",
    "\n",
    "# Tests for specific issues in uniqueness of values,\n",
    "def unique_values_test(metadata1, metadata2):\n",
    "    #assigns problem number and type to differences in unique values\n",
    "    problems = np.array([])\n",
    "    for ind in metadata1.index:\n",
    "        unique_value_difference = metadata1['number_unique_values'][ind] - metadata2['number_unique_values'][ind]\n",
    "        unique_ratio_difference = metadata1['column_unique_ratio'][ind] - metadata2['column_unique_ratio'][ind]\n",
    "\n",
    "        if((unique_value_difference < 0) and (abs(unique_ratio_difference) > .05)):\n",
    "           #finding number of problems, type\n",
    "           problems = np.append(problems, \"problems: \" + str(abs(unique_value_difference))+ \", new unique values(ratio not normal)\")\n",
    "        else:\n",
    "            if(unique_value_difference < 0):\n",
    "                problems = np.append(problems, \"problems: \" + str(abs(unique_value_difference))+ \", new unique values(ratio normal)\")\n",
    "            \n",
    "            else:\n",
    "                if(abs(unique_ratio_difference) > .05):\n",
    "                    problems = np.append(problems,\"unique ratio difference issue: \"+ str(unique_ratio_difference))\n",
    "                else:\n",
    "                    problems = np.append(problems, \"ordinary\")\n",
    "    return problems\n",
    "    \n",
    "metadata_tester(metadata1, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checks for extraneous html tags: if we haven't seen one before, why should we see one now?\n",
    "def html_test(meta1, meta2):\n",
    "    html_check = np.array([])\n",
    "    for ind in meta1.index:\n",
    "        tags1 = meta1['num_html_tags'][ind]\n",
    "        tags2 = meta2['num_html_tags'][ind]\n",
    "        if((tags1 == 0) and (tags2 != 0)):\n",
    "            html_check = np.append(html_check, \"problems: \" + str(tags2) +\", extraneous html tags\")\n",
    "        else:\n",
    "            # Potential issues in training set itself\n",
    "            if(tags1 != 0):\n",
    "                html_check = np.append(html_check, \"training set contains html tags\")\n",
    "            else:\n",
    "                html_check = np.append(html_check,\"ordinary\")\n",
    "    print(html_check)\n",
    "    return html_check\n",
    "\n",
    "# If nan is a unique value we already test for that, but what if there is an unusually high/low number of nan's?\n",
    "# Could that be attributed to user error?\n",
    "def nan_test(meta1, meta2):\n",
    "    nan_array = np.array([])\n",
    "    nan_diff = meta1['nan_ratio'] - meta2['nan_ratio']\n",
    "    vals = abs(nan_diff)\n",
    "    for val in vals:\n",
    "        if(abs(val) > .05):\n",
    "            nan_array = np.append(nan_arrray, \"unusual change in nan-number:\" + val )\n",
    "        else:\n",
    "            nan_array = np.append(nan_array, \"ordinary\")\n",
    "    return nan_array\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any numeric Columns you would consider categorical?\n",
      "no\n",
      "['ordinary' 'ordinary' 'ordinary' 'ordinary']\n",
      "                                                   unique_value_status  \\\n",
      "categorical_columns                                                      \n",
      "budget_cycle                                                  ordinary   \n",
      "fund_type                                                     ordinary   \n",
      "dept_name              problems: 11.0, new unique values(ratio normal)   \n",
      "account              problems: 26.0, new unique values(ratio not no...   \n",
      "\n",
      "                    html_tag_status nan_status  \n",
      "categorical_columns                             \n",
      "budget_cycle               ordinary   ordinary  \n",
      "fund_type                  ordinary   ordinary  \n",
      "dept_name                  ordinary   ordinary  \n",
      "account                    ordinary   ordinary  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>report_fy</th>\n",
       "      <th>budget_cycle</th>\n",
       "      <th>fund_type</th>\n",
       "      <th>fund_number</th>\n",
       "      <th>dept_name</th>\n",
       "      <th>funds_center_number</th>\n",
       "      <th>account</th>\n",
       "      <th>account_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>379363.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>Salaried Wages</td>\n",
       "      <td>500011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>139001.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>CERS - General Retirement</td>\n",
       "      <td>502012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7650.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>Supp Pens Sav Plan Mandatory</td>\n",
       "      <td>502021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7778.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>Supp Pens Sav Plan Voluntary</td>\n",
       "      <td>502022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7650.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>CERS-UAAL Unclass-Unrepresented</td>\n",
       "      <td>502043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3646.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>Workers' Comp Insurance</td>\n",
       "      <td>502046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36109.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>Flexible Benefit Plan</td>\n",
       "      <td>502047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3066.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>Risk Mgmt Administration</td>\n",
       "      <td>502048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1207.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>Long Term Disability</td>\n",
       "      <td>502049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>690.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>Unemployment Insurance</td>\n",
       "      <td>502050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5501.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>Fica/Medicare Insurance</td>\n",
       "      <td>502051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17745.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>Retiree Health Contribution</td>\n",
       "      <td>502052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>310.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>Employer Contrib RMT</td>\n",
       "      <td>502077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11441.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>SPSP-H General Members</td>\n",
       "      <td>502094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>511010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>200.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>Postage/Mailing</td>\n",
       "      <td>511011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>Computer Accessories</td>\n",
       "      <td>511048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>800.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>Copier Paper</td>\n",
       "      <td>511117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>1 Day Trips-Less Than 200 Miles</td>\n",
       "      <td>512000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>500.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>Fees-Membership</td>\n",
       "      <td>512043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>500.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>Meals With Non-City Employees</td>\n",
       "      <td>512057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>15438.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>Miscellaneous Professional/Technical Ser</td>\n",
       "      <td>512059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>750.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>Parking Stamps</td>\n",
       "      <td>512064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>Training-In Town</td>\n",
       "      <td>512070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>Travel-Non Training</td>\n",
       "      <td>512072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>500.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>Travel-Training</td>\n",
       "      <td>512073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>Photocopy Services</td>\n",
       "      <td>512077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>Print Shop Services</td>\n",
       "      <td>512080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>763.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>Interfund Environmental Services</td>\n",
       "      <td>512108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8289.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Office of the Chief Operating Officer, normal ...</td>\n",
       "      <td>1001000011</td>\n",
       "      <td>SAP Support Allocation</td>\n",
       "      <td>512162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>2093.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Council Administration count outlier: new valu...</td>\n",
       "      <td>1151000011</td>\n",
       "      <td>Network Access - Discretionary</td>\n",
       "      <td>513004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>2372.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Council Administration count outlier: new valu...</td>\n",
       "      <td>1151000011</td>\n",
       "      <td>Hardware/Software - Discretionary: unique valu...</td>\n",
       "      <td>513104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>5909.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Council Administration count outlier: new valu...</td>\n",
       "      <td>1151000011</td>\n",
       "      <td>Help Desk and Desktop Support</td>\n",
       "      <td>513210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>11231.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Council Administration count outlier: new valu...</td>\n",
       "      <td>1151000011</td>\n",
       "      <td>Data Center</td>\n",
       "      <td>513211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>21288.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Council Administration count outlier: new valu...</td>\n",
       "      <td>1151000011</td>\n",
       "      <td>Voice/Data Network</td>\n",
       "      <td>513212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>1530.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Council Administration count outlier: new valu...</td>\n",
       "      <td>1151000011</td>\n",
       "      <td>Satellite/Cable Services: unique value: unique...</td>\n",
       "      <td>514008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>1032.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Council Administration count outlier: new valu...</td>\n",
       "      <td>1151000011</td>\n",
       "      <td>Cellular Phone Operating Cost</td>\n",
       "      <td>514009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>79800.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Council Administration count outlier: new valu...</td>\n",
       "      <td>1151000011</td>\n",
       "      <td>Electric Services</td>\n",
       "      <td>514100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>2665.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Council Administration count outlier: new valu...</td>\n",
       "      <td>1151000011</td>\n",
       "      <td>Gas Services</td>\n",
       "      <td>514101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>250.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Council Administration count outlier: new valu...</td>\n",
       "      <td>1151000011</td>\n",
       "      <td>Wireless Communication Transfer</td>\n",
       "      <td>514112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>4100.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Council Administration count outlier: new valu...</td>\n",
       "      <td>1151000011</td>\n",
       "      <td>Transportation Allowance</td>\n",
       "      <td>516015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>10442.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Council Administration count outlier: new valu...</td>\n",
       "      <td>1151000011</td>\n",
       "      <td>Information Technology Services Transfer</td>\n",
       "      <td>516021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>2500.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>Council Administration count outlier: new valu...</td>\n",
       "      <td>1151000011</td>\n",
       "      <td>Cap Exp-Equipment: unique value: unique value:...</td>\n",
       "      <td>560040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>150030.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>City Clerk count outlier: new value: unique va...</td>\n",
       "      <td>1152000001</td>\n",
       "      <td>Salaried Wages</td>\n",
       "      <td>500011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>81781.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>City Clerk count outlier: new value: unique va...</td>\n",
       "      <td>1152000001</td>\n",
       "      <td>CERS - General Retirement</td>\n",
       "      <td>502012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>4501.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>City Clerk count outlier: new value: unique va...</td>\n",
       "      <td>1152000001</td>\n",
       "      <td>Supp Pens Sav Plan Mandatory</td>\n",
       "      <td>502021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>4576.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>City Clerk count outlier: new value: unique va...</td>\n",
       "      <td>1152000001</td>\n",
       "      <td>Supp Pens Sav Plan Voluntary</td>\n",
       "      <td>502022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>4501.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>City Clerk count outlier: new value: unique va...</td>\n",
       "      <td>1152000001</td>\n",
       "      <td>CERS-UAAL Unclass-Unrepresented</td>\n",
       "      <td>502043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>750.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>City Clerk count outlier: new value: unique va...</td>\n",
       "      <td>1152000001</td>\n",
       "      <td>Workers' Comp Insurance</td>\n",
       "      <td>502046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>13953.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>City Clerk count outlier: new value: unique va...</td>\n",
       "      <td>1152000001</td>\n",
       "      <td>Flexible Benefit Plan</td>\n",
       "      <td>502047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>1022.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>City Clerk count outlier: new value: unique va...</td>\n",
       "      <td>1152000001</td>\n",
       "      <td>Risk Mgmt Administration</td>\n",
       "      <td>502048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>477.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>City Clerk count outlier: new value: unique va...</td>\n",
       "      <td>1152000001</td>\n",
       "      <td>Long Term Disability</td>\n",
       "      <td>502049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>273.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>City Clerk count outlier: new value: unique va...</td>\n",
       "      <td>1152000001</td>\n",
       "      <td>Unemployment Insurance</td>\n",
       "      <td>502050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>2175.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>City Clerk count outlier: new value: unique va...</td>\n",
       "      <td>1152000001</td>\n",
       "      <td>Fica/Medicare Insurance</td>\n",
       "      <td>502051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>5915.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>City Clerk count outlier: new value: unique va...</td>\n",
       "      <td>1152000001</td>\n",
       "      <td>Retiree Health Contribution</td>\n",
       "      <td>502052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>257379.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>City Clerk count outlier: new value: unique va...</td>\n",
       "      <td>1152000011</td>\n",
       "      <td>Salaried Wages</td>\n",
       "      <td>500011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>32496.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>City Clerk count outlier: new value: unique va...</td>\n",
       "      <td>1152000011</td>\n",
       "      <td>Vacation Pay In Lieu: unique value: unique val...</td>\n",
       "      <td>500017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1456.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>City Clerk count outlier: new value: unique va...</td>\n",
       "      <td>1152000011</td>\n",
       "      <td>Bilingual - Regular: unique value: unique valu...</td>\n",
       "      <td>500055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>74729.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>City Clerk count outlier: new value: unique va...</td>\n",
       "      <td>1152000011</td>\n",
       "      <td>CERS - General Retirement</td>\n",
       "      <td>502012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>5352.0</td>\n",
       "      <td>17</td>\n",
       "      <td>adopted</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>100000</td>\n",
       "      <td>City Clerk count outlier: new value: unique va...</td>\n",
       "      <td>1152000011</td>\n",
       "      <td>Supp Pens Sav Plan Mandatory</td>\n",
       "      <td>502021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       amount  report_fy budget_cycle     fund_type  fund_number  \\\n",
       "0    379363.0         17      adopted  General Fund       100000   \n",
       "1    139001.0         17      adopted  General Fund       100000   \n",
       "2      7650.0         17      adopted  General Fund       100000   \n",
       "3      7778.0         17      adopted  General Fund       100000   \n",
       "4      7650.0         17      adopted  General Fund       100000   \n",
       "5      3646.0         17      adopted  General Fund       100000   \n",
       "6     36109.0         17      adopted  General Fund       100000   \n",
       "7      3066.0         17      adopted  General Fund       100000   \n",
       "8      1207.0         17      adopted  General Fund       100000   \n",
       "9       690.0         17      adopted  General Fund       100000   \n",
       "10     5501.0         17      adopted  General Fund       100000   \n",
       "11    17745.0         17      adopted  General Fund       100000   \n",
       "12      310.0         17      adopted  General Fund       100000   \n",
       "13    11441.0         17      adopted  General Fund       100000   \n",
       "14     2000.0         17      adopted  General Fund       100000   \n",
       "15      200.0         17      adopted  General Fund       100000   \n",
       "16     1000.0         17      adopted  General Fund       100000   \n",
       "17      800.0         17      adopted  General Fund       100000   \n",
       "18     1000.0         17      adopted  General Fund       100000   \n",
       "19      500.0         17      adopted  General Fund       100000   \n",
       "20      500.0         17      adopted  General Fund       100000   \n",
       "21    15438.0         17      adopted  General Fund       100000   \n",
       "22      750.0         17      adopted  General Fund       100000   \n",
       "23     6000.0         17      adopted  General Fund       100000   \n",
       "24    20000.0         17      adopted  General Fund       100000   \n",
       "25      500.0         17      adopted  General Fund       100000   \n",
       "26     1000.0         17      adopted  General Fund       100000   \n",
       "27     1500.0         17      adopted  General Fund       100000   \n",
       "28      763.0         17      adopted  General Fund       100000   \n",
       "29     8289.0         17      adopted  General Fund       100000   \n",
       "..        ...        ...          ...           ...          ...   \n",
       "470    2093.0         17      adopted  General Fund       100000   \n",
       "471    2372.0         17      adopted  General Fund       100000   \n",
       "472    5909.0         17      adopted  General Fund       100000   \n",
       "473   11231.0         17      adopted  General Fund       100000   \n",
       "474   21288.0         17      adopted  General Fund       100000   \n",
       "475    1530.0         17      adopted  General Fund       100000   \n",
       "476    1032.0         17      adopted  General Fund       100000   \n",
       "477   79800.0         17      adopted  General Fund       100000   \n",
       "478    2665.0         17      adopted  General Fund       100000   \n",
       "479     250.0         17      adopted  General Fund       100000   \n",
       "480    4100.0         17      adopted  General Fund       100000   \n",
       "481   10442.0         17      adopted  General Fund       100000   \n",
       "482    2500.0         17      adopted  General Fund       100000   \n",
       "483  150030.0         17      adopted  General Fund       100000   \n",
       "484   81781.0         17      adopted  General Fund       100000   \n",
       "485    4501.0         17      adopted  General Fund       100000   \n",
       "486    4576.0         17      adopted  General Fund       100000   \n",
       "487    4501.0         17      adopted  General Fund       100000   \n",
       "488     750.0         17      adopted  General Fund       100000   \n",
       "489   13953.0         17      adopted  General Fund       100000   \n",
       "490    1022.0         17      adopted  General Fund       100000   \n",
       "491     477.0         17      adopted  General Fund       100000   \n",
       "492     273.0         17      adopted  General Fund       100000   \n",
       "493    2175.0         17      adopted  General Fund       100000   \n",
       "494    5915.0         17      adopted  General Fund       100000   \n",
       "495  257379.0         17      adopted  General Fund       100000   \n",
       "496   32496.0         17      adopted  General Fund       100000   \n",
       "497    1456.0         17      adopted  General Fund       100000   \n",
       "498   74729.0         17      adopted  General Fund       100000   \n",
       "499    5352.0         17      adopted  General Fund       100000   \n",
       "\n",
       "                                             dept_name  funds_center_number  \\\n",
       "0    Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "1    Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "2    Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "3    Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "4    Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "5    Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "6    Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "7    Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "8    Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "9    Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "10   Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "11   Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "12   Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "13   Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "14   Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "15   Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "16   Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "17   Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "18   Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "19   Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "20   Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "21   Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "22   Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "23   Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "24   Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "25   Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "26   Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "27   Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "28   Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "29   Office of the Chief Operating Officer, normal ...           1001000011   \n",
       "..                                                 ...                  ...   \n",
       "470  Council Administration count outlier: new valu...           1151000011   \n",
       "471  Council Administration count outlier: new valu...           1151000011   \n",
       "472  Council Administration count outlier: new valu...           1151000011   \n",
       "473  Council Administration count outlier: new valu...           1151000011   \n",
       "474  Council Administration count outlier: new valu...           1151000011   \n",
       "475  Council Administration count outlier: new valu...           1151000011   \n",
       "476  Council Administration count outlier: new valu...           1151000011   \n",
       "477  Council Administration count outlier: new valu...           1151000011   \n",
       "478  Council Administration count outlier: new valu...           1151000011   \n",
       "479  Council Administration count outlier: new valu...           1151000011   \n",
       "480  Council Administration count outlier: new valu...           1151000011   \n",
       "481  Council Administration count outlier: new valu...           1151000011   \n",
       "482  Council Administration count outlier: new valu...           1151000011   \n",
       "483  City Clerk count outlier: new value: unique va...           1152000001   \n",
       "484  City Clerk count outlier: new value: unique va...           1152000001   \n",
       "485  City Clerk count outlier: new value: unique va...           1152000001   \n",
       "486  City Clerk count outlier: new value: unique va...           1152000001   \n",
       "487  City Clerk count outlier: new value: unique va...           1152000001   \n",
       "488  City Clerk count outlier: new value: unique va...           1152000001   \n",
       "489  City Clerk count outlier: new value: unique va...           1152000001   \n",
       "490  City Clerk count outlier: new value: unique va...           1152000001   \n",
       "491  City Clerk count outlier: new value: unique va...           1152000001   \n",
       "492  City Clerk count outlier: new value: unique va...           1152000001   \n",
       "493  City Clerk count outlier: new value: unique va...           1152000001   \n",
       "494  City Clerk count outlier: new value: unique va...           1152000001   \n",
       "495  City Clerk count outlier: new value: unique va...           1152000011   \n",
       "496  City Clerk count outlier: new value: unique va...           1152000011   \n",
       "497  City Clerk count outlier: new value: unique va...           1152000011   \n",
       "498  City Clerk count outlier: new value: unique va...           1152000011   \n",
       "499  City Clerk count outlier: new value: unique va...           1152000011   \n",
       "\n",
       "                                               account  account_number  \n",
       "0                                       Salaried Wages          500011  \n",
       "1                            CERS - General Retirement          502012  \n",
       "2                         Supp Pens Sav Plan Mandatory          502021  \n",
       "3                         Supp Pens Sav Plan Voluntary          502022  \n",
       "4                      CERS-UAAL Unclass-Unrepresented          502043  \n",
       "5                              Workers' Comp Insurance          502046  \n",
       "6                                Flexible Benefit Plan          502047  \n",
       "7                             Risk Mgmt Administration          502048  \n",
       "8                                 Long Term Disability          502049  \n",
       "9                               Unemployment Insurance          502050  \n",
       "10                             Fica/Medicare Insurance          502051  \n",
       "11                         Retiree Health Contribution          502052  \n",
       "12                                Employer Contrib RMT          502077  \n",
       "13                              SPSP-H General Members          502094  \n",
       "14                                     Office Supplies          511010  \n",
       "15                                     Postage/Mailing          511011  \n",
       "16                                Computer Accessories          511048  \n",
       "17                                        Copier Paper          511117  \n",
       "18                     1 Day Trips-Less Than 200 Miles          512000  \n",
       "19                                     Fees-Membership          512043  \n",
       "20                       Meals With Non-City Employees          512057  \n",
       "21            Miscellaneous Professional/Technical Ser          512059  \n",
       "22                                      Parking Stamps          512064  \n",
       "23                                    Training-In Town          512070  \n",
       "24                                 Travel-Non Training          512072  \n",
       "25                                     Travel-Training          512073  \n",
       "26                                  Photocopy Services          512077  \n",
       "27                                 Print Shop Services          512080  \n",
       "28                    Interfund Environmental Services          512108  \n",
       "29                              SAP Support Allocation          512162  \n",
       "..                                                 ...             ...  \n",
       "470                     Network Access - Discretionary          513004  \n",
       "471  Hardware/Software - Discretionary: unique valu...          513104  \n",
       "472                      Help Desk and Desktop Support          513210  \n",
       "473                                        Data Center          513211  \n",
       "474                                 Voice/Data Network          513212  \n",
       "475  Satellite/Cable Services: unique value: unique...          514008  \n",
       "476                      Cellular Phone Operating Cost          514009  \n",
       "477                                  Electric Services          514100  \n",
       "478                                       Gas Services          514101  \n",
       "479                    Wireless Communication Transfer          514112  \n",
       "480                           Transportation Allowance          516015  \n",
       "481           Information Technology Services Transfer          516021  \n",
       "482  Cap Exp-Equipment: unique value: unique value:...          560040  \n",
       "483                                     Salaried Wages          500011  \n",
       "484                          CERS - General Retirement          502012  \n",
       "485                       Supp Pens Sav Plan Mandatory          502021  \n",
       "486                       Supp Pens Sav Plan Voluntary          502022  \n",
       "487                    CERS-UAAL Unclass-Unrepresented          502043  \n",
       "488                            Workers' Comp Insurance          502046  \n",
       "489                              Flexible Benefit Plan          502047  \n",
       "490                           Risk Mgmt Administration          502048  \n",
       "491                               Long Term Disability          502049  \n",
       "492                             Unemployment Insurance          502050  \n",
       "493                            Fica/Medicare Insurance          502051  \n",
       "494                        Retiree Health Contribution          502052  \n",
       "495                                     Salaried Wages          500011  \n",
       "496  Vacation Pay In Lieu: unique value: unique val...          500017  \n",
       "497  Bilingual - Regular: unique value: unique valu...          500055  \n",
       "498                          CERS - General Retirement          502012  \n",
       "499                       Supp Pens Sav Plan Mandatory          502021  \n",
       "\n",
       "[500 rows x 9 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function tests for the specific underlying problem, only in columns where testing actually needs to be done\n",
    "def categorical_reasoning(data, problem_meta, old_data):\n",
    "    print(problem_meta)\n",
    "    for ind in problem_meta.index:\n",
    "        uniqueness = problem_meta['unique_value_status'][ind]\n",
    "        html =  problem_meta['html_tag_status'][ind]\n",
    "        nans =  problem_meta['nan_status'][ind]\n",
    "        #If value is ordinary, no need to check for anything else. Otherwise, we determine specific root of the problem \n",
    "        #and conduct further testing.\n",
    "        if(uniqueness != 'ordinary'):\n",
    "            unique = return_unique(old_data[ind])\n",
    "            if('ratio not normal' in uniqueness):\n",
    "                new_data = np.array([])\n",
    "                for i in data.get(ind):\n",
    "                    new_data = np.append(new_data, unique_modifier(i,unique))\n",
    "                data[ind] = new_data\n",
    "            else:\n",
    "                if('ratio normal' in uniqueness):\n",
    "                    new_data = np.array([])\n",
    "                    for i in data.get(ind):\n",
    "                        new_data = np.append(new_data, unique_modifier(i,unique))\n",
    "                    data[ind] = new_data \n",
    "                else:\n",
    "                    print(\"the ratio of unique values in column '\" + ind +\"' has significantly changed\")               \n",
    "        # Simplest case: ordinary / extraneous / appear in training set\n",
    "        if(html != 'ordinary'): \n",
    "            if('extraneous html' in html):\n",
    "                for i in data[ind][i]:\n",
    "                    if(has_tag(data[ind][i])):\n",
    "                        data[ind][i] = \"Extraneous tag\"\n",
    "            else:\n",
    "                print(\"Your training set appears to have html tags, so the program assumes these are OK\")\n",
    "        if(nans != 'ordinary'):\n",
    "            print(\"Column \" + ind + \" has an unusually high number of NaN values, and the program has identified this to be problematic\")\n",
    "    return data\n",
    "\n",
    "#Returns unique values of a list\n",
    "def return_unique(data):\n",
    "    return np.unique(data)\n",
    "\n",
    "#Returns a statement with either the non-unique categorical value as given by the initial training set, or the value\n",
    "# combined with a string proclaiming that it is uniqu|e.\n",
    "def unique_modifier(data, value_set):\n",
    "    if(data in value_set):\n",
    "         return data\n",
    "    else:\n",
    "        return data +': unique value'\n",
    "    \n",
    "categorical_reasoning(table, metadata_tester(metadata1, table), table.head(50))\n",
    "\n",
    "\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Anomaly Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report will give the user a detailed picture of: is something wrong with their data, where is it, and hopefully why that is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning colors to problematic values (still grouped with indices so easy to tell)\n",
    "# Yellow: mild concern, Orange: serious concern, red - major concern\n",
    "def designer(frame):\n",
    "    threshold1 = 5\n",
    "    threshold2 = 20\n",
    "    threshold3 = 40\n",
    "    print(\"Would you like to reset default issue alert thresholds?\")\n",
    "    if(input().upper() == 'YES'):\n",
    "        print(\"Mild concern threshold (in probability (percentage) of issue being present):\")\n",
    "        threshold1 = float(input())\n",
    "        print(\"Moderate concern threshold (in probability (percentage) of issue being present)\")\n",
    "        threshold2 = float(input())\n",
    "        print(\"Serious concern threshold (in probability (percentage) of issue being present)\")\n",
    "        threshold3 = float(input())\n",
    "    temp = pcaPrep(frame)\n",
    "    styler = frame.style\n",
    "    for col in temp.columns:\n",
    "        frame = styler.applymap(lambda x: 'background-color: %s' % 'yellow' if x > threshold1 else 'background-color: %s' % 'light-gray', subset = [col])\n",
    "        frame = styler.applymap(lambda x: 'background-color: %s' % 'orange' if x > threshold2 else 'background-color: %s' % 'light-gray', subset = [col])\n",
    "        frame = styler.applymap(lambda x: 'background-color: %s' % 'red' if x > threshold3 else 'background-color: %s' % 'light-gray', subset = [col])\n",
    "    return frame \n",
    "       \n",
    "designer(surpriseTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
