{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood\n",
    "### open source data quality monitor\n",
    "\n",
    "Colin Jemmott\n",
    "2020\n",
    "\n",
    "Have you ever found out an ETL job failed because a customer called?  You ever retrain a machine learning model in production just to find out the data changed out from under you?  Have a dashboard break because new data violated your assumptions?\n",
    "\n",
    "### Approach\n",
    "\n",
    "Everything is probability (or, rather [surprise](https://en.wikipedia.org/wiki/Entropy_(information_theory)#Introduction)!).  Works on a two dataframes for now - you have to get the data.\n",
    "\n",
    "Batch job, you pass in training and test.\n",
    "\n",
    "Taxonomy of problems for initial launch:\n",
    "- New values in categorical - bootstrapping\n",
    "- Missing values - bootstrapping (Nan is just another category)\n",
    "- Outliers in counts (missing or spike) - prophet\n",
    "\n",
    "To Do:\n",
    "\n",
    "- Outliers in counts of groups - bootstrapping\n",
    "- Outliers in values - kernel density?\n",
    "\n",
    "Later:\n",
    "- Outliers in correlation between categories - assocation rules / Bayesian network / just conditional probability\n",
    "- Delayed data (I think we need a writtenAt timestamp)\n",
    "- Multi-table: check joins\n",
    "- PCA?  Other anomaly detection?\n",
    "- Multitenant\n",
    "\n",
    "### Tips\n",
    "\n",
    "Some of the analysis assumes that the data is stationary (ergodic).  If that is a bad assumption it might make sense to trim history.  maxTrainingSizeMultiple controls that.\n",
    "\n",
    "### To Do\n",
    "\n",
    "- Change out data for something public (SDPD?)\n",
    "- Write params to JSON\n",
    "- preprocessor on bootsrtapping for columns with tons of entries.  Also numerical columns?\n",
    "- Throw a warning or error if the testing sample is too small?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math as mt\n",
    "import dateutil\n",
    "from datetime import datetime, timedelta\n",
    "import requests as rd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from sklearn import neighbors, decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data\n",
    "\n",
    "Not part of the actual product, but here for ease of testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "N_days = 90\n",
    "batchHours = 7*24 # this grabs the most recent chunk and looks for differences with the remainder\n",
    "\n",
    "\n",
    "# parameters (will put into JSON config file later)\n",
    "params = {\"fName\": \"pd_calls_for_service_2020_datasd.csv\", # local CSV file only right now\n",
    "          \"ts\": \"date_time\", # Timestamp for when the event happened in the world\n",
    "          \"bootstrapResamples\":1000, # should probably be 10k for better accuracy, but much worse speed\n",
    "          \"maxTrainingSizeMultiple\":10, # if there is more than X times more training data, trim to most recent\n",
    "          \"maxCategories\":100, # maximum number of categories in a column - if higher we skip\n",
    "          \"minCategoryCount\":10, # don't report boostrap surprise if a category has lower count\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data, split into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"pd_calls_for_service_2020_datasd.csv\")\n",
    "if(df.shape[0] <= 1000):\n",
    "    print(\"Warning: small data set might produce inaccurate results\")\n",
    "df['ts'] = df[params['ts']]\n",
    "print(df)\n",
    "#.apply(dateutil.parser.parse, ignoretz=True) # could speed this up for ISO8601 - currently slow.\n",
    "df['ts'] =  pd.to_datetime(df['ts'], format='%Y%m%d %H:%M:%S')\n",
    "maxTs = max(df['ts'])\n",
    "#df = df.assign(date_time = df.get(\"date_time\").apply(datetime.strptime, args = (\"%d/%m/%Y %H:%M:%S\")))\n",
    "batchTs = maxTs - timedelta(hours = batchHours)\n",
    "testDf = df[df['ts'] > batchTs]\n",
    "trainDf = df[df['ts'] < batchTs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(trainDf['ts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers and Math\n",
    "def pValue(data, threshold):\n",
    "    p_larger = sum(np.array(data) >= threshold) / len(data)\n",
    "    p_smaller = sum(np.array(data) <= threshold) / len(data)\n",
    "    p = min(p_larger, p_smaller)\n",
    "\n",
    "    # only use gaussian p-value when there is variation, but bootsrap p = 0\n",
    "    stdev = np.std(data)\n",
    "    if stdev == 0 or p != 0:\n",
    "        p_gauss = p\n",
    "    else:\n",
    "        p_gauss = scipy.stats.norm(np.mean(result['bootstrap_counts']), stdev).cdf(result['count'])\n",
    "        p_gauss = min(p_gauss,1-p_gauss)\n",
    "    return p_gauss\n",
    "\n",
    "def trimTraining(trainDf, params):\n",
    "\n",
    "    # trim to most recent\n",
    "    trainDf = trainDf.sort_values(params['ts'], ascending =False)\n",
    "    trainDfTrimmed = trainDf[:params['maxTrainingSizeMultiple']*len(testDf)]\n",
    "    \n",
    "    return trainDfTrimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all of the string columns\n",
    "columnNames = []\n",
    "for columnName in testDf.keys():\n",
    "    if (type (testDf[columnName].iloc[0])) == str:\n",
    "        columnNames.append(columnName)\n",
    "print(columnNames)\n",
    "bootstrapDf = trimTraining(trainDf, params)\n",
    "        \n",
    "# set up dict, add counts\n",
    "results = {}\n",
    "for columnName in columnNames:\n",
    "    # if it isn't a string column, reject it\n",
    "    if type(testDf[columnName].iloc[0]) != str:\n",
    "        continue\n",
    "    categories = (bootstrapDf[columnName].append(testDf[columnName])).unique()\n",
    "    if len(categories) > params['maxCategories']:\n",
    "        continue\n",
    "    \n",
    "    results[columnName] = {}\n",
    "    testCounts = testDf[columnName].value_counts(dropna = False)\n",
    "    for i in np.arange(1,len(categories) -1):\n",
    "        if(pd.isna(categories[i])):\n",
    "            categories = np.delete(categories, i)  \n",
    "    for category in categories:\n",
    "        results[columnName][category] = {'bootstrap_counts':[],\n",
    "                                        'count':testCounts.get(category,0)}\n",
    "# resample, add boostrap counts\n",
    "for ii in range(params['bootstrapResamples']):\n",
    "    # Draw random sample from training\n",
    "    sampleDf = bootstrapDf.sample(len(testDf), replace=True)\n",
    "    for columnName in results.keys():\n",
    "        # count by category\n",
    "        trainCounts = sampleDf[columnName].value_counts(dropna = False)\n",
    "        # put results in dict\n",
    "        for category in results[columnName].keys():\n",
    "            boostrapCount = trainCounts.get(category,0)\n",
    "            results[columnName][category]['bootstrap_counts'].append(boostrapCount)\n",
    "              \n",
    "# convert to records, add p-values\n",
    "bootstrap_results = []\n",
    "for columnName in results.keys():\n",
    "    for category in results[columnName].keys():\n",
    "        result = results[columnName][category]\n",
    "        \n",
    "        estimatedCount = int(np.round(np.mean(result['bootstrap_counts'])))\n",
    "        # don't report entries with very low predicted and actual counts\n",
    "        if estimatedCount < params['minCategoryCount'] and result['count'] < params['minCategoryCount']:\n",
    "            continue\n",
    "        \n",
    "        p = pValue(result['bootstrap_counts'],result['count'])\n",
    "        categoryName = category\n",
    "        if not category:\n",
    "            categoryName = \"NULL\"\n",
    "        \n",
    "        bootstrap_results.append({\"column\":columnName,\n",
    "                           \"category\":categoryName,\n",
    "                           \"count\":result['count'],\n",
    "                           \"p\": p,\n",
    "                           \"estimated_count\":estimatedCount,\n",
    "                           })\n",
    "if(np.count_nonzero(p)>0):\n",
    "    resultsDf = pd.DataFrame.from_records(bootstrap_results).sort_values('p')\n",
    "    resultsDf['surprise'] = -np.log2(resultsDf['p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsDf.head(70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timeseries forecast (prophet)\n",
    "\n",
    "Installing prophet is a major pain, especially on Windows.  Details: https://facebook.github.io/prophet/docs/installation.html\n",
    "\n",
    "Following the lead from Seismic interns: https://medium.com/seismic-data-science/anomaly-detection-using-prophet-a5dcea2c5473\n",
    "\n",
    "Decided to go hourly, but could change to day with a few tweaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncateTs(ts):\n",
    "    return ts.replace(minute=0, second=0,  microsecond=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncatedData = trainDf['ts'].apply(truncateTs)\n",
    "groupedCounts = truncatedData.value_counts()\n",
    "\n",
    "prophetDf = pd.DataFrame({'ds':groupedCounts.index,'y':np.log10(groupedCounts.values)})\n",
    "prophetDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find number of hours to preduct: ceil of hours in testDf\n",
    "timeDelta = max(testDf['ts']) -min(testDf['ts'])\n",
    "hours = int(timeDelta.days*24 + timeDelta.seconds/(60*60))+1\n",
    " \n",
    "# Train model\n",
    "m = Prophet(#daily_seasonality = True, \n",
    "            #yearly_seasonality = False, \n",
    "            #weekly_seasonality = True, \n",
    "            #growth='linear',\n",
    "            interval_width=0.68 # one sigma\n",
    "           )\n",
    "m.add_country_holidays(country_name='US')\n",
    "\n",
    "m.fit(prophetDf)\n",
    "\n",
    "future = m.make_future_dataframe(periods = hours, freq = 'H')\n",
    "fcst = m.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the test data\n",
    "truncatedData = testDf['ts'].apply(truncateTs)\n",
    "groupedCounts = truncatedData.value_counts()\n",
    "\n",
    "prophetTestDf = pd.DataFrame({'ds':groupedCounts.index,\n",
    "                              'y':np.log10(groupedCounts.values),\n",
    "                              'y_linear':groupedCounts.values})\n",
    "\n",
    "# find p-value\n",
    "prophet_results = []\n",
    "\n",
    "for ii in range(len(prophetTestDf)):\n",
    "    ts = prophetTestDf['ds'][ii]\n",
    "    fcstExample = fcst[fcst['ds'] == ts]\n",
    "    mean = fcstExample['yhat'].iloc[0]\n",
    "    stdev = (fcstExample['yhat_upper'].iloc[0] - fcstExample['yhat_lower'].iloc[0])/2\n",
    "    p = scipy.stats.norm(mean, stdev).cdf(prophetTestDf['y'][ii])\n",
    "    p = min(p,1-p)\n",
    "\n",
    "    prophet_results.append({\"column\":\"Forecast\",\n",
    "                       \"category\":str(ts),\n",
    "                       \"count\":prophetTestDf['y_linear'][ii],\n",
    "                       \"p\": p,\n",
    "                       \"estimated_count\":int(np.round(np.power(10,mean))),\n",
    "                       })\n",
    "    \n",
    "prophetResultsDf = pd.DataFrame.from_records(prophet_results).sort_values('p')\n",
    "prophetResultsDf['surprise'] = -np.log2(prophetResultsDf['p'])\n",
    "prophetResultsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting for debug only\n",
    "fig = m.plot(fcst)\n",
    "fig = m.plot_components(fcst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Density Implementation Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtaining user input\n",
    "#https://www.nbastuffer.com/2019-2020-nba-team-stats/\n",
    "def inp(default = 1, default2 = \"https://www.nbastuffer.com/2019-2020-nba-team-stats/\"):\n",
    "    if(default2 != \"https://www.nbastuffer.com/2019-2020-nba-team-stats/\"):\n",
    "        nam = input()\n",
    "    else:\n",
    "        nam = default2\n",
    "    frame = pd.read_html(nam)\n",
    "    first_table = frame[default]\n",
    "    return first_table\n",
    "first_table = inp(1,\"input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stat Computations for Formulas Found Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def getParam(default = \"PTS/GMPoints Per GameAverage points per game\"):\n",
    "    #Stuff beyond here focuses on kernel density, it is a work in progress\n",
    "    if(default != \"PTS/GMPoints Per GameAverage points per game\"):\n",
    "        print(\"Enter the column name you'd like to get a kernel density estimation for:\")\n",
    "        #Prompting user for input and calculating basic statistics, bandwidth temporarily set to .05\n",
    "        #For testing purposes\n",
    "        inp = input()\n",
    "    else:\n",
    "        inp = default\n",
    "    stat = first_table.get(inp)\n",
    "    return stat\n",
    "stat = getParam()\n",
    "#Index for purpose of making table nicer\n",
    "def getIndex(indx = \"TEAM\"):\n",
    "    if(indx!=\"TEAM\"):\n",
    "        print(\"Please enter the name of the column you'd like to serve as your index:\")\n",
    "        indx = first_table.get(input())\n",
    "    else:\n",
    "        indx = first_table.get(indx)\n",
    "    return indx\n",
    "indx = getIndex()\n",
    "\n",
    "#Plotting Data initially\n",
    "stat.plot(kind  = \"hist\")\n",
    "avg = stat.mean()\n",
    "density = np.array([])\n",
    "n = first_table.shape[0]\n",
    "dev = np.std(stat)\n",
    "\n",
    "kernelEstimations = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kernel Estimation for a Gaussian, Cosine, Triangular, and Parabolic Kernel are found below, metric used for surprise computation will be based on their average. Idea is: if between them we can found a standard density, we can find values that are more likely to be outliers. Other idea: find outliers for every one and check for commonalities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit learn citation because their software is utilized\n",
    "@article{scikit-learn,\n",
    " title={Scikit-learn: Machine Learning in {P}ython},\n",
    " author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.\n",
    "         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.\n",
    "         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and\n",
    "         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},\n",
    " journal={Journal of Machine Learning Research},\n",
    " volume={12},\n",
    " pages={2825--2830},\n",
    " year={2011}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using cosine kernel function to get estimate for log density\n",
    "def cosKernel(stat):\n",
    "    stat = stat.to_numpy().reshape(-1,1) \n",
    "    l = neighbors.KernelDensity(kernel = 'cosine').fit(stat)\n",
    "    cos_density = l.score_samples(stat)\n",
    "    return cos_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using gaussian kernel function to get estimate for log density\n",
    "def gaussKernel(stat):\n",
    "    stat = stat.to_numpy().reshape(-1,1) \n",
    "    l = neighbors.KernelDensity(kernel = 'gaussian').fit(stat)\n",
    "    density = l.score_samples(stat)\n",
    "    return density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using linear kernel function to get estimate for log density\n",
    "def expKernel(stat):\n",
    "    stat = stat.to_numpy().reshape(-1,1) \n",
    "    l = neighbors.KernelDensity(kernel = 'exponential').fit(stat)\n",
    "    triDensity = l.score_samples(stat)\n",
    "    return triDensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converted to Proportion for u < 1 supported functions\n",
    "def toProp(number):\n",
    "    return number/max(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using epanechnikov kernel function to get estimate for log density\n",
    "def parabolicKernel(stat):\n",
    "    stat = stat.to_numpy().reshape(-1,1) \n",
    "    l = neighbors.KernelDensity(kernel = 'epanechnikov').fit(stat)\n",
    "    epDensity = l.score_samples(stat)\n",
    "    return epDensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates normal distribution (we have standardized data) and calculates P-value with the null hypothesis being no systematic error\n",
    "def retPVal(col):\n",
    "    #Since we have a normal distribution, starting by obtaining the z-score\n",
    "    mean = col.mean()\n",
    "    std = np.std(col)\n",
    "    array = np.array([])\n",
    "    for i in np.arange(len(col)):\n",
    "        array = np.append(array, col.iloc[i] - mean)\n",
    "    \n",
    "    #Now obtaining legitimate p-values\n",
    "    z_scores = array/std\n",
    "    for l in np.arange(len(z_scores)):\n",
    "        cdf = st.norm.cdf(z_scores[l])\n",
    "        z_scores[l] = min(cdf, 1-cdf)\n",
    "    return pd.Series(z_scores, index = col.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Values Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning initial kernal estimations\n",
    "def kernelEstimator(indx, stat):\n",
    "    kernelEstimate = pd.DataFrame()\n",
    "    kernelEstimate = kernelEstimate.assign(Data_Index = indx, Data_Point = stat,Gaussian = gaussKernel(stat),\n",
    "                                               Epanechnikov = parabolicKernel(stat), Exponential = expKernel(stat),\n",
    "                                               Cosine = cosKernel(stat))\n",
    "    # temporary sort for some visualization of surprise\n",
    "    kernelEstimate = kernelEstimate.sort_values(by = \"Gaussian\", ascending = False)\n",
    "    return kernelEstimate\n",
    "kernelEstimation = kernelEstimator(indx, stat)\n",
    "kernelEstimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating their average\n",
    "def surprise_estimator(kernelEstimation):\n",
    "    numDevMax = (kernelEstimation.get(\"Data_Point\").max() - kernelEstimation.get(\"Data_Point\").mean())/kernelEstimation.get(\"Data_Point\").std()\n",
    "    numDevMin = (kernelEstimation.get(\"Data_Point\").min() - kernelEstimation.get(\"Data_Point\").mean())/kernelEstimation.get(\"Data_Point\").std()\n",
    "    numDev = max(numDevMax, numDevMin)\n",
    "    if(numDev > 3.2):\n",
    "        metric = retPVal(kernelEstimation.get(\"Exponential\"))\n",
    "    elif((numDev <=3.2) & (numDev >= 2)):\n",
    "        metric = retPVal(kernelEstimation.get(\"Gaussian\"))\n",
    "    else:\n",
    "        metric = retPVal(kernelEstimation.get(\"Exponential\")+kernelEstimation.get(\"Epanechnikov\"))          \n",
    "    # Surprise Metric\n",
    "    kernelEstimation  = kernelEstimation.assign(Surprise = -np.log2(metric))\n",
    "    kernelEstimation = kernelEstimation.sort_values(by = \"Surprise\", ascending = False)\n",
    "    return kernelEstimation\n",
    "kernelEstimation = surprise_estimator(kernelEstimation)\n",
    "kernelEstimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A grouping of the entire kernel estimation process\n",
    "def surprise_Table(Table, index = \"TEAM\"):\n",
    "    temp = pcaPrep(Table)\n",
    "    if(isinstance(index, str)):\n",
    "        index = Table.get(index)\n",
    "    sum_surprise  = pd.Series(np.zeros(Table.shape[0]))\n",
    "    for col in temp.columns:\n",
    "        stat = temp.get(col)\n",
    "        KernelTable = kernelEstimator(index, stat)\n",
    "        KernelTable = surprise_estimator(KernelTable)\n",
    "        Table[col] = KernelTable.get(\"Surprise\")\n",
    "        sum_surprise+=Table[col]\n",
    "    sum_surprise = sum_surprise.array\n",
    "    if(not isinstance(index, str)):\n",
    "        Table = Table.set_index(index)\n",
    "    Table = Table.assign(mean_surprise = np.round(sum_surprise/Table.shape[1],2))\n",
    "    # Sorting table for easier visualization\n",
    "    Table = Table.sort_values(by = \"mean_surprise\", ascending  = False)\n",
    "    return Table\n",
    "modTable = first_table\n",
    "surpriseTable = surprise_Table(first_table)\n",
    "surpriseTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Exponential Density should apply to a more fat-tailed distribution, and makes less assumption of outliers, others assume a less spread out (parabolic and cosine) or normal (gaussian) distribution. To truly quantify an outlier, exponential density should be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surpriseTable.plot(kind = \"barh\", y = \"mean_surprise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surpriseTable.get(\"mean_surprise\").plot(kind = \"hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA and Singular Value Decomp for Cross Column Correlation Lie Ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import smtplib\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader(first_table):\n",
    "    # Giving user option to change dataset\n",
    "    print(\"Would you like to change the data set you are working with?\")\n",
    "    if(input().upper() == \"YES\"):\n",
    "        print(\"Enter the URL below:\")\n",
    "        nam = input()\n",
    "        frame = pd.read_html(nam)\n",
    "        table = frame[1]\n",
    "        return table\n",
    "    else:\n",
    "        return first_table\n",
    "first_table = loader(first_table)\n",
    "print(\"\\ndataset below:\")\n",
    "first_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pcaPrep(first_table):\n",
    "# Finding all numerical components of the table so that pca can function\n",
    "    tabl = first_table.select_dtypes(include = [np.number])\n",
    "    tabl = tabl.dropna(1)\n",
    "    return tabl\n",
    "\n",
    "def obtain_variance_table(first_table):\n",
    "    tabl = pcaPrep(first_table)\n",
    "    scaled_data = StandardScaler().fit_transform(tabl)\n",
    "    # Creating a PCA object \n",
    "    pca = PCA(n_components = (tabl.shape[1]))\n",
    "    pcaData = pca.fit_transform(scaled_data)\n",
    "    infoFrame = pd.DataFrame().assign(Column = [\"PC\" + str(i) for i in range(tabl.shape[1])], Variance_ratio = pca.explained_variance_ratio_ )\n",
    "    return infoFrame\n",
    "obtain_variance_table(first_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtainPCAVals(componentNum, scaled_data):\n",
    "    pca = PCA(n_components = componentNum)\n",
    "    print(scaled_data)\n",
    "    pcaData = pca.fit_transform(scaled_data)\n",
    "    return pcaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deciding how many columns need to be used: utilizing threashold of 95% of the explained variance\n",
    "def elementDecider(infoFrame):\n",
    "    numSum = 0\n",
    "    counter = 0\n",
    "    for i in infoFrame.get(\"Variance_ratio\"):\n",
    "        if(numSum < .95):\n",
    "            numSum += i\n",
    "            counter+=1\n",
    "    return counter\n",
    "\n",
    "#Reducing dimensionality of data into pc's, only storing what is neccessary\n",
    "def reducedData(infoFrame,  scaled_data, indx):\n",
    "    numCols = elementDecider(infoFrame)\n",
    "    pcaData = obtainPCAVals(numCols, scaled_data)\n",
    "    pcaFrame = pd.DataFrame(pcaData)\n",
    "    if(not isinstance(indx, str)):\n",
    "        pcaFrame = pcaFrame.set_index(indx)\n",
    "    return pcaFrame\n",
    "\n",
    "#Visualization tool for seeing grouping of elements by pc\n",
    "def displayReducedData(pcaVals, xNum = 0, yNum = 1):\n",
    "    # Ensuring that the elements given do not overacess table \n",
    "    if(xNum < pcaVals.shape[1]) & (yNum < pcaVals.shape[1]):\n",
    "        pcaVals.plot(kind = \"scatter\", x = 2, y = 3)\n",
    "    else:\n",
    "        print(\"You have overaccessed the number of elements, keep in mind there are only \" + str(pcaVals.shape[1]) + \" elements\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summing p-values because PCA serves to check for systematic bias, whereas kernel density checks for accuracy\n",
    "def sumRows(pcaVals):\n",
    "    sumArray = np.zeros(pcaVals.shape[0])\n",
    "    for i in np.arange(pcaVals.shape[1]):\n",
    "        values = pcaVals.get(str(i)).array\n",
    "        sumArray += values\n",
    "    sumArray /= pcaVals.shape[1]\n",
    "    #After obtaining sum, the average deviation from the expected value is averaged out, not taking in absolute value\n",
    "    # to check for systematic error\n",
    "    return sumArray\n",
    "\n",
    "    \n",
    "def pcaRowOutliers(pcaVals):\n",
    "    P_val_table = pd.DataFrame()\n",
    "    #Creating a table of all the PCA p-values\n",
    "    for col in np.arange(0,pcaVals.shape[1]):\n",
    "        P_vals =  retPVal(pcaVals.get(col))\n",
    "        i = str(col)\n",
    "        P_val_table[i] = P_vals\n",
    "    print(\"The P-Values of each PCA score found below: \\n\")\n",
    "    print(P_val_table)\n",
    "    totalVar = sumRows(P_val_table)\n",
    "    \n",
    "    #Calculating surprise by taking negative log\n",
    "    newVals = pcaVals.assign(Surprise = -np.log2(totalVar))\n",
    "    newVals = newVals.sort_values(by = \"Surprise\", ascending = False)\n",
    "    return newVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runPCA(table, index):\n",
    "    processing_table = pcaPrep(table)\n",
    "    variance_table = obtain_variance_table(table)\n",
    "    pcaVals = reducedData(variance_table, StandardScaler().fit_transform(processing_table), table.get(index))\n",
    "    new_pca = pcaRowOutliers(pcaVals)\n",
    "    return new_pca\n",
    "new_pca = runPCA(first_table, 'TEAM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have found individual outliers with both a column approach and a row-based approach, we group the 2 approaches using naive bayes in a manner that is easy to read. Idea: group by sum of surprise so outliers appear at the top!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_kernel_combo(pcaTable,kernelTable):\n",
    "    pcaSurpriseCol = new_pca.get(\"Surprise\")\n",
    "    temp = pcaPrep(kernelTable)\n",
    "    for column in temp.columns:\n",
    "        kernelTable[column] = (kernelTable[column].multiply(pcaSurpriseCol)).apply(np.sqrt)\n",
    "    kernelTable = kernelTable.sort_values(by = \"mean_surprise\", ascending = False)\n",
    "    return kernelTable\n",
    "surpriseTable = pca_kernel_combo(new_pca, surpriseTable) \n",
    "surpriseTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attaching Program to Data Set Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.read_csv(\"http://seshat.datasd.org/budget/budget_operating_datasd.csv\", nrows = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = (table.groupby(\"account_number\").mean()).reset_index()\n",
    "print(table)\n",
    "def main(table):\n",
    "    kernelTable = surprise_Table(table, 10)\n",
    "    pcaTable = runPCA(table, table.get(\"account_number\"))\n",
    "    combo = pca_kernel_combo(pcaTable, kernelTable)\n",
    "    return designer(combo)\n",
    "main(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import schedule\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule.every().friday.do(main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tackling the Categorical Question Below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are several categorical questions that could be tackled with this program, ultimately, this will be used in the report which assesses flaws in the data. I perceive the functionality to work something like a data spellcheck. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, the question of is there a problem with the data and where is it will have already been answered by the time this section is utilized. This will attempt to answer why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some questions to be answered\n",
    "1)Did the user make a simple typo? \n",
    "2)Does the data fit previous specifications? Has the metadata changed?\n",
    "3)Are previously unseen values now appearing?\n",
    "4)Can NAN's be surprising, how so?\n",
    "5)Are extraneous HTML and CSS tags lying around?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach: Use metadata to check for anomalies, and if an anomaly is found over a certain threshold conduct a spellcheck or excessive tag check on it. For sake of efficiency, this will first test for certain issues within specific coluns as a whole based on metadata, and any that exist will be located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein as leven\n",
    "from pandas.api.types import is_numeric_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any numeric Columns you would consider categorical?\n",
      "yes\n",
      "Enter one such column:\n",
      "RANK]\n",
      "Any more?\n",
      "no\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['budget_cycle', 'fund_type', 'dept_name', 'account', 'RANK]']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Will examine whether or not a column is categorical, giving the user the opportunity to add additional numeric columns\n",
    "def identifyCategorical(surpriseFrame):\n",
    "    categorical_list = []\n",
    "    for col in surpriseFrame.columns:\n",
    "        if(not(is_numeric_dtype(surpriseFrame[col]))):\n",
    "            categorical_list.append(col)\n",
    "    \n",
    "    # Allows fixing of default assumption that numeric columns aren't categorical\n",
    "    print(\"Are there any numeric Columns you would consider categorical?\")\n",
    "    while(input().upper() == \"YES\"):\n",
    "        print(\"Enter one such column:\")\n",
    "        categorical_list.append(input())\n",
    "        print(\"Any more?\")\n",
    "    return categorical_list\n",
    "\n",
    "# We want to preserve initial NaN's, so passing first_table instead of modified surpriseTable\n",
    "categorical_columns = identifyCategorical(table)\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Has the value been historically Unique?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any numeric Columns you would consider categorical?\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "# Determines uniqueness ratios to determine whether a unique/nonunique value is an anomaly\n",
    "#Returns ratios for metaData data frame in next method\n",
    "def unique_ratio(surpriseFrame, categorical_columns):\n",
    "    ratios = np.array([])\n",
    "    \n",
    "    # Removing NaN's because they can be treated as 0 for this purpose, this way we can identify them as a non-unique value\n",
    "    surpriseFrame = surpriseFrame.replace({np.nan:0})\n",
    "    for column in categorical_columns:\n",
    "        ratios = np.append(ratios, len(np.unique(surpriseFrame.get(column).to_numpy()))/ surpriseFrame.shape[0])   \n",
    "    return ratios\n",
    "\n",
    "#Obtaining sample size for sake of metadata comparisons and possible p-value calculation PER sample size\n",
    "def sampleSizeArray(table, categorical_columns):\n",
    "    array = np.array([])\n",
    "    for i in categorical_columns:\n",
    "        array = np.append(array, table.shape[0])\n",
    "    return array\n",
    "\n",
    "# Builds DataFrame full of metadata off of given training set that is to be used for later comparisons\n",
    "def metaData(table):\n",
    "        metadata_table = pd.DataFrame()\n",
    "        categorical_cols = identifyCategorical(table)\n",
    "        uniqueness = unique_ratio(table, categorical_cols)\n",
    "        \n",
    "        # Number and ratio of unique values to be used for detection of anomalies in the appearance of new values\n",
    "        metadata_table = metadata_table.assign(categorical_columns = categorical_cols, column_unique_ratio = uniqueness)\n",
    "        metadata_table = metadata_table.assign(number_unique_values = np.round(uniqueness*table.shape[0]))\n",
    "        metadata_table = metadata_table.assign(nan_ratio = nan_ratio(table, categorical_cols)).set_index(\"categorical_columns\")\n",
    "        \n",
    "        #obtaining sample size, number of html tags\n",
    "        metadata_table = metadata_table.assign(based_off_sample = sampleSizeArray(table, categorical_cols) )\n",
    "        metadata_table = metadata_table.assign(num_html_tags = contains_HTML(table, categorical_cols))\n",
    "        return metadata_table\n",
    "metadata1 = metaData(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting NaN's to determine if a missing value is an anomaly, or a larger than usual NaN ratio is:\n",
    "def nan_ratio(frame, categorical_columns):\n",
    "    nan_ratio = np.array([])\n",
    "    for column in categorical_columns:\n",
    "        nans = frame.get(column).apply(isNan).to_numpy()\n",
    "        nan_ratio = np.append(nan_ratio, np.count_nonzero(nans)/frame.shape[0])\n",
    "    return nan_ratio\n",
    "\n",
    "# NaN's aren't equal to themselves\n",
    "def isNan(x):\n",
    "    return x!=x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If there are only several unique values, appends them to the Data Frame\n",
    "def contains_HTML(table, categorical_columns):\n",
    "    html_array = np.array([])\n",
    "    for i in categorical_columns:\n",
    "        tag_bools = table.get(i).apply(has_tag)\n",
    "        html_array = np.append(html_array,np.count_nonzero(tag_bools))\n",
    "    return html_array\n",
    "\n",
    "# Checks if a single entry of any data type contains an html tag\n",
    "def has_tag(entry):\n",
    "    entry = str(entry)\n",
    "    return ('<' in entry or '>' in entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any numeric Columns you would consider categorical?\n",
      "no\n",
      "['ordinary' 'ordinary' 'ordinary' 'ordinary']\n",
      "                                       unique_value_status html_tag_status\n",
      "categorical_columns                                                       \n",
      "budget_cycle                                      ordinary        ordinary\n",
      "fund_type                                         ordinary        ordinary\n",
      "dept_name                                         ordinary        ordinary\n",
      "account              unique ratio difference issue: -0.776        ordinary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_value_status</th>\n",
       "      <th>html_tag_status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categorical_columns</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>budget_cycle</th>\n",
       "      <td>ordinary</td>\n",
       "      <td>ordinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fund_type</th>\n",
       "      <td>ordinary</td>\n",
       "      <td>ordinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dept_name</th>\n",
       "      <td>ordinary</td>\n",
       "      <td>ordinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>account</th>\n",
       "      <td>unique ratio difference issue: -0.776</td>\n",
       "      <td>ordinary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       unique_value_status html_tag_status\n",
       "categorical_columns                                                       \n",
       "budget_cycle                                      ordinary        ordinary\n",
       "fund_type                                         ordinary        ordinary\n",
       "dept_name                                         ordinary        ordinary\n",
       "account              unique ratio difference issue: -0.776        ordinary"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tests for all potential issues, returns issue + severity\n",
    "# Idea: should user be able to disable default tests?\n",
    "def metadata_tester(metadata1, chosen_data):\n",
    "    problem_meta = pd.DataFrame()\n",
    "    metadata2 = metaData(chosen_data)\n",
    "    problem_meta = problem_meta.assign(unique_value_status = unique_values_test(metadata1, metadata2)).set_index(metadata1.index)\n",
    "    problem_meta = problem_meta.assign(html_tag_status = html_test(metadata1, metadata2))\n",
    "    print(problem_meta)\n",
    "    return problem_meta\n",
    "\n",
    "# Tests for specific issues in uniqueness of values,\n",
    "def unique_values_test(metadata1, metadata2, ):\n",
    "    #assigns problem number and type to differences in unique values\n",
    "    problems = np.array([])\n",
    "    for ind in metadata1.index:\n",
    "        unique_value_difference = metadata1['number_unique_values'][ind] - metadata2['number_unique_values'][ind]\n",
    "        unique_ratio_difference = metadata1['column_unique_ratio'][ind] - metadata2['column_unique_ratio'][ind]\n",
    "\n",
    "        if((unique_value_difference < 0) and (abs(unique_ratio_difference) > .05)):\n",
    "           #finding number of problems, type\n",
    "           problems = np.append(problems, \"problems: \" + str(abs(unique_value_difference))+ \", new unique values(ratio not normal)\")\n",
    "        else:\n",
    "            if(unique_value_difference < 0):\n",
    "                problems = np.append(problems, \"problems: \" + str(abs(unique_value_difference))+ \", new unique values(ratio normal)\")\n",
    "            \n",
    "            else:\n",
    "                if(abs(unique_ratio_difference) > .05):\n",
    "                    problems = np.append(problems,\"unique ratio difference issue: \"+ str(unique_ratio_difference))\n",
    "                else:\n",
    "                    problems = np.append(problems, \"ordinary\")\n",
    "    return problems\n",
    "    \n",
    "metadata_tester(metadata1, table.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checks for extraneous html tags: if we haven't seen one before, why should we see one now?\n",
    "def html_test(meta1, meta2):\n",
    "    html_check = np.array([])\n",
    "    for ind in meta1.index:\n",
    "        tags1 = meta1['num_html_tags'][ind]\n",
    "        tags2 = meta2['num_html_tags'][ind]\n",
    "        if((tags1 == 0) and (tags2 != 0)):\n",
    "            html_check = np.append(html_check, \"problems: \" + str(tags2) +\", extraneous html tags\")\n",
    "        else:\n",
    "            # Potential issues in training set itself\n",
    "            if(tags1 != 0):\n",
    "                html_check = np.append(html_check, \"training set contains html tags\")\n",
    "            else:\n",
    "                html_check = np.append(html_check,\"ordinary\")\n",
    "    print(html_check)\n",
    "    return html_check\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Anomaly Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report will give the user a detailed picture of: is something wrong with their data, where is it, and hopefully why that is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning colors to problematic values (still grouped with indices so easy to tell)\n",
    "# Yellow: mild concern, Orange: serious concern, red - major concern\n",
    "def designer(frame):\n",
    "    threshold1 = 5\n",
    "    threshold2 = 20\n",
    "    threshold3 = 40\n",
    "    print(\"Would you like to reset default issue alert thresholds?\")\n",
    "    if(input().upper() == 'YES'):\n",
    "        print(\"Mild concern threshold (in probability (percentage) of issue being present):\")\n",
    "        threshold1 = float(input())\n",
    "        print(\"Moderate concern threshold (in probability (percentage) of issue being present)\")\n",
    "        threshold2 = float(input())\n",
    "        print(\"Serious concern threshold (in probability (percentage) of issue being present)\")\n",
    "        threshold3 = float(input())\n",
    "    temp = pcaPrep(frame)\n",
    "    styler = frame.style\n",
    "    for col in temp.columns:\n",
    "        frame = styler.applymap(lambda x: 'background-color: %s' % 'yellow' if x > threshold1 else 'background-color: %s' % 'light-gray', subset = [col])\n",
    "        frame = styler.applymap(lambda x: 'background-color: %s' % 'orange' if x > threshold2 else 'background-color: %s' % 'light-gray', subset = [col])\n",
    "        frame = styler.applymap(lambda x: 'background-color: %s' % 'red' if x > threshold3 else 'background-color: %s' % 'light-gray', subset = [col])\n",
    "    return frame \n",
    "       \n",
    "designer(surpriseTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
